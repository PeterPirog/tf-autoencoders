{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "01-mnist-VAE_v3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPGTrRlo/BCLjPI6vF2hOyw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PeterPirog/tf-autoencoders/blob/main/01_mnist_VAE_v3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://keras.io/examples/generative/vae/\n",
        "Latent vector length =3\n",
        "\n",
        "https://harvard-iacs.github.io/2019-CS109B/labs/lab10/VAE-solutions/"
      ],
      "metadata": {
        "id": "BYzxx-LJDxRh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "0MDe9j_fDpu7"
      },
      "outputs": [],
      "source": [
        "# Setup\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "EPOCHS=1000  # for vae training\n",
        "latent_dim = 2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a sampling layer\n",
        "\n",
        "class Sampling(layers.Layer):\n",
        "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
        "\n",
        "    def call(self, inputs):\n",
        "        z_mean, z_log_var = inputs\n",
        "        batch = tf.shape(z_mean)[0]\n",
        "        dim = tf.shape(z_mean)[1]\n",
        "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
        "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n"
      ],
      "metadata": {
        "id": "azwMsEScD6fJ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the encoder\n",
        "\n",
        "encoder_inputs = keras.Input(shape=(28, 28, 1))\n",
        "x = layers.Conv2D(32, 3, activation=\"relu\", strides=2, padding=\"same\")(encoder_inputs)\n",
        "x = layers.Conv2D(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
        "x = layers.Flatten()(x)\n",
        "x = layers.Dense(16, activation=\"relu\")(x)\n",
        "z_mean = layers.Dense(latent_dim, name=\"z_mean\")(x)\n",
        "z_log_var = layers.Dense(latent_dim, name=\"z_log_var\")(x)\n",
        "z = Sampling()([z_mean, z_log_var])\n",
        "encoder = keras.Model(encoder_inputs, [z_mean, z_log_var, z], name=\"encoder\")\n",
        "encoder.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jLxM8eNaD-6a",
        "outputId": "bb81c24a-01e4-4bc2-dab6-a566d3d64dac"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"encoder\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 28, 28, 1)]  0           []                               \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 14, 14, 32)   320         ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 7, 7, 64)     18496       ['conv2d[0][0]']                 \n",
            "                                                                                                  \n",
            " flatten (Flatten)              (None, 3136)         0           ['conv2d_1[0][0]']               \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 16)           50192       ['flatten[0][0]']                \n",
            "                                                                                                  \n",
            " z_mean (Dense)                 (None, 2)            34          ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " z_log_var (Dense)              (None, 2)            34          ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " sampling (Sampling)            (None, 2)            0           ['z_mean[0][0]',                 \n",
            "                                                                  'z_log_var[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 69,076\n",
            "Trainable params: 69,076\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the decoder\n",
        "\n",
        "latent_inputs = keras.Input(shape=(latent_dim,))\n",
        "x = layers.Dense(7 * 7 * 64, activation=\"relu\")(latent_inputs)\n",
        "x = layers.Reshape((7, 7, 64))(x)\n",
        "x = layers.Conv2DTranspose(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
        "x = layers.Conv2DTranspose(32, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
        "decoder_outputs = layers.Conv2DTranspose(1, 3, activation=\"sigmoid\", padding=\"same\")(x)\n",
        "decoder = keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n",
        "decoder.summary()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7BKuO7GHEDpB",
        "outputId": "6322ff2e-c3b8-4fca-da5c-96815cb5df3f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"decoder\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 2)]               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 3136)              9408      \n",
            "                                                                 \n",
            " reshape (Reshape)           (None, 7, 7, 64)          0         \n",
            "                                                                 \n",
            " conv2d_transpose (Conv2DTra  (None, 14, 14, 64)       36928     \n",
            " nspose)                                                         \n",
            "                                                                 \n",
            " conv2d_transpose_1 (Conv2DT  (None, 28, 28, 32)       18464     \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " conv2d_transpose_2 (Conv2DT  (None, 28, 28, 1)        289       \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 65,089\n",
            "Trainable params: 65,089\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the VAE as a Model with a custom train_step\n",
        "\n",
        "class VAE(keras.Model):\n",
        "    def __init__(self, encoder, decoder, **kwargs):\n",
        "        super(VAE, self).__init__(**kwargs)\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
        "        self.reconstruction_loss_tracker = keras.metrics.Mean(\n",
        "            name=\"reconstruction_loss\"\n",
        "        )\n",
        "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [\n",
        "            self.total_loss_tracker,\n",
        "            self.reconstruction_loss_tracker,\n",
        "            self.kl_loss_tracker,\n",
        "        ]\n",
        "\n",
        "    def train_step(self, data):\n",
        "        with tf.GradientTape() as tape:\n",
        "            z_mean, z_log_var, z = self.encoder(data)\n",
        "            reconstruction = self.decoder(z)\n",
        "            reconstruction_loss = tf.reduce_mean(\n",
        "                tf.reduce_sum(\n",
        "                    keras.losses.binary_crossentropy(data, reconstruction), axis=(1, 2)\n",
        "                )\n",
        "            )\n",
        "            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
        "            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n",
        "            total_loss = reconstruction_loss + kl_loss\n",
        "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
        "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
        "        self.total_loss_tracker.update_state(total_loss)\n",
        "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
        "        self.kl_loss_tracker.update_state(kl_loss)\n",
        "        return {\n",
        "            \"loss\": self.total_loss_tracker.result(),\n",
        "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
        "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
        "        }\n",
        "\n"
      ],
      "metadata": {
        "id": "JL5qVupYEIEi"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks_vae=[tf.keras.callbacks.ReduceLROnPlateau(monitor='loss', \n",
        "                                                factor=0.5,\n",
        "                                                patience=3,\n",
        "                                                min_lr=1e-5),\n",
        "           tf.keras.callbacks.EarlyStopping(monitor='loss',\n",
        "                                            patience=5)]"
      ],
      "metadata": {
        "id": "Hh6ebn3aHXL5"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the VAE\n",
        "\n",
        "(x_train, _), (x_test, _) = keras.datasets.mnist.load_data()\n",
        "mnist_digits = np.concatenate([x_train, x_test], axis=0)\n",
        "mnist_digits = np.expand_dims(mnist_digits, -1).astype(\"float32\") / 255\n",
        "\n",
        "vae = VAE(encoder, decoder)\n",
        "vae.compile(optimizer=keras.optimizers.Adam())\n",
        "vae.fit(mnist_digits, epochs=EPOCHS, batch_size=128,callbacks=callbacks_vae)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DCe0H3MSEPsa",
        "outputId": "9d8788e5-daed-4262-9fb1-ecf8a5cc4b97"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n",
            "Epoch 1/1000\n",
            "547/547 [==============================] - 23s 19ms/step - loss: 260.8973 - reconstruction_loss: 204.8499 - kl_loss: 2.5273 - lr: 0.0010\n",
            "Epoch 2/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 168.2813 - reconstruction_loss: 161.6228 - kl_loss: 4.8039 - lr: 0.0010\n",
            "Epoch 3/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 163.0515 - reconstruction_loss: 156.6547 - kl_loss: 5.1404 - lr: 0.0010\n",
            "Epoch 4/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 159.8430 - reconstruction_loss: 154.1896 - kl_loss: 5.3241 - lr: 0.0010\n",
            "Epoch 5/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 157.9745 - reconstruction_loss: 152.5732 - kl_loss: 5.4640 - lr: 0.0010\n",
            "Epoch 6/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 157.2225 - reconstruction_loss: 151.3737 - kl_loss: 5.5535 - lr: 0.0010\n",
            "Epoch 7/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 156.1915 - reconstruction_loss: 150.5677 - kl_loss: 5.6290 - lr: 0.0010\n",
            "Epoch 8/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 155.3432 - reconstruction_loss: 149.6956 - kl_loss: 5.7073 - lr: 0.0010\n",
            "Epoch 9/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 154.8402 - reconstruction_loss: 149.1530 - kl_loss: 5.7498 - lr: 0.0010\n",
            "Epoch 10/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 154.4759 - reconstruction_loss: 148.6522 - kl_loss: 5.7757 - lr: 0.0010\n",
            "Epoch 11/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 153.6619 - reconstruction_loss: 148.1134 - kl_loss: 5.8524 - lr: 0.0010\n",
            "Epoch 12/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 153.4997 - reconstruction_loss: 147.7169 - kl_loss: 5.8653 - lr: 0.0010\n",
            "Epoch 13/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 153.3759 - reconstruction_loss: 147.2573 - kl_loss: 5.8989 - lr: 0.0010\n",
            "Epoch 14/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 152.8165 - reconstruction_loss: 147.0162 - kl_loss: 5.9383 - lr: 0.0010\n",
            "Epoch 15/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 152.4061 - reconstruction_loss: 146.6560 - kl_loss: 5.9772 - lr: 0.0010\n",
            "Epoch 16/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 151.9462 - reconstruction_loss: 146.3361 - kl_loss: 5.9793 - lr: 0.0010\n",
            "Epoch 17/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 151.7989 - reconstruction_loss: 146.0761 - kl_loss: 6.0161 - lr: 0.0010\n",
            "Epoch 18/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 151.9896 - reconstruction_loss: 145.7985 - kl_loss: 6.0194 - lr: 0.0010\n",
            "Epoch 19/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 151.7804 - reconstruction_loss: 145.5913 - kl_loss: 6.0661 - lr: 0.0010\n",
            "Epoch 20/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 151.3597 - reconstruction_loss: 145.3269 - kl_loss: 6.0759 - lr: 0.0010\n",
            "Epoch 21/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 150.9872 - reconstruction_loss: 145.2572 - kl_loss: 6.0891 - lr: 0.0010\n",
            "Epoch 22/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 150.9262 - reconstruction_loss: 145.0491 - kl_loss: 6.1042 - lr: 0.0010\n",
            "Epoch 23/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 150.7046 - reconstruction_loss: 144.7959 - kl_loss: 6.1161 - lr: 0.0010\n",
            "Epoch 24/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 150.6275 - reconstruction_loss: 144.7297 - kl_loss: 6.1347 - lr: 0.0010\n",
            "Epoch 25/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 150.8137 - reconstruction_loss: 144.5063 - kl_loss: 6.1592 - lr: 0.0010\n",
            "Epoch 26/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 150.2727 - reconstruction_loss: 144.3409 - kl_loss: 6.1645 - lr: 0.0010\n",
            "Epoch 27/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 150.5950 - reconstruction_loss: 144.2252 - kl_loss: 6.1740 - lr: 0.0010\n",
            "Epoch 28/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 150.1199 - reconstruction_loss: 144.0597 - kl_loss: 6.1859 - lr: 0.0010\n",
            "Epoch 29/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 149.8285 - reconstruction_loss: 143.9855 - kl_loss: 6.2088 - lr: 0.0010\n",
            "Epoch 30/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 149.7892 - reconstruction_loss: 143.8367 - kl_loss: 6.2135 - lr: 0.0010\n",
            "Epoch 31/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 149.9720 - reconstruction_loss: 143.6306 - kl_loss: 6.2296 - lr: 0.0010\n",
            "Epoch 32/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 149.3685 - reconstruction_loss: 143.5855 - kl_loss: 6.2320 - lr: 0.0010\n",
            "Epoch 33/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 149.7290 - reconstruction_loss: 143.4405 - kl_loss: 6.2424 - lr: 0.0010\n",
            "Epoch 34/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 149.2929 - reconstruction_loss: 143.3485 - kl_loss: 6.2645 - lr: 0.0010\n",
            "Epoch 35/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 149.5481 - reconstruction_loss: 143.2555 - kl_loss: 6.2911 - lr: 0.0010\n",
            "Epoch 36/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 149.0114 - reconstruction_loss: 143.1347 - kl_loss: 6.2785 - lr: 0.0010\n",
            "Epoch 37/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 149.4327 - reconstruction_loss: 143.1374 - kl_loss: 6.2738 - lr: 0.0010\n",
            "Epoch 38/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 149.0579 - reconstruction_loss: 142.9487 - kl_loss: 6.2851 - lr: 0.0010\n",
            "Epoch 39/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 148.9756 - reconstruction_loss: 142.7646 - kl_loss: 6.3215 - lr: 0.0010\n",
            "Epoch 40/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 149.1786 - reconstruction_loss: 142.7834 - kl_loss: 6.3459 - lr: 0.0010\n",
            "Epoch 41/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 149.0892 - reconstruction_loss: 142.5900 - kl_loss: 6.3439 - lr: 0.0010\n",
            "Epoch 42/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 149.1015 - reconstruction_loss: 142.5297 - kl_loss: 6.3584 - lr: 0.0010\n",
            "Epoch 43/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 148.7675 - reconstruction_loss: 142.4605 - kl_loss: 6.3661 - lr: 0.0010\n",
            "Epoch 44/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 148.5167 - reconstruction_loss: 142.3545 - kl_loss: 6.3648 - lr: 0.0010\n",
            "Epoch 45/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 148.9691 - reconstruction_loss: 142.2496 - kl_loss: 6.3901 - lr: 0.0010\n",
            "Epoch 46/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 148.5102 - reconstruction_loss: 142.1765 - kl_loss: 6.4026 - lr: 0.0010\n",
            "Epoch 47/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 148.4662 - reconstruction_loss: 142.1040 - kl_loss: 6.3913 - lr: 0.0010\n",
            "Epoch 48/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 148.4638 - reconstruction_loss: 141.9773 - kl_loss: 6.4155 - lr: 0.0010\n",
            "Epoch 49/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 148.2164 - reconstruction_loss: 141.9095 - kl_loss: 6.4164 - lr: 0.0010\n",
            "Epoch 50/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 148.1406 - reconstruction_loss: 141.7834 - kl_loss: 6.4188 - lr: 0.0010\n",
            "Epoch 51/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 148.2460 - reconstruction_loss: 141.7621 - kl_loss: 6.4143 - lr: 0.0010\n",
            "Epoch 52/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 148.0754 - reconstruction_loss: 141.7128 - kl_loss: 6.4466 - lr: 0.0010\n",
            "Epoch 53/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 147.5965 - reconstruction_loss: 141.6455 - kl_loss: 6.4402 - lr: 0.0010\n",
            "Epoch 54/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 147.9089 - reconstruction_loss: 141.5213 - kl_loss: 6.4462 - lr: 0.0010\n",
            "Epoch 55/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 147.7229 - reconstruction_loss: 141.4139 - kl_loss: 6.4427 - lr: 0.0010\n",
            "Epoch 56/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 147.7331 - reconstruction_loss: 141.4380 - kl_loss: 6.4677 - lr: 0.0010\n",
            "Epoch 57/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 147.6475 - reconstruction_loss: 141.3023 - kl_loss: 6.4754 - lr: 0.0010\n",
            "Epoch 58/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 147.7358 - reconstruction_loss: 141.2337 - kl_loss: 6.4768 - lr: 0.0010\n",
            "Epoch 59/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 147.7318 - reconstruction_loss: 141.2835 - kl_loss: 6.4760 - lr: 0.0010\n",
            "Epoch 60/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 147.3628 - reconstruction_loss: 141.0909 - kl_loss: 6.4914 - lr: 0.0010\n",
            "Epoch 61/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 147.2772 - reconstruction_loss: 141.1282 - kl_loss: 6.4834 - lr: 0.0010\n",
            "Epoch 62/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 147.3837 - reconstruction_loss: 140.9822 - kl_loss: 6.4985 - lr: 0.0010\n",
            "Epoch 63/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 147.4924 - reconstruction_loss: 140.9423 - kl_loss: 6.5156 - lr: 0.0010\n",
            "Epoch 64/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 147.3060 - reconstruction_loss: 140.8889 - kl_loss: 6.4969 - lr: 0.0010\n",
            "Epoch 65/1000\n",
            "547/547 [==============================] - 11s 19ms/step - loss: 147.3172 - reconstruction_loss: 140.8243 - kl_loss: 6.5217 - lr: 0.0010\n",
            "Epoch 66/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 147.2002 - reconstruction_loss: 140.8494 - kl_loss: 6.5074 - lr: 0.0010\n",
            "Epoch 67/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 147.1502 - reconstruction_loss: 140.6510 - kl_loss: 6.5248 - lr: 0.0010\n",
            "Epoch 68/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 147.0883 - reconstruction_loss: 140.6234 - kl_loss: 6.5302 - lr: 0.0010\n",
            "Epoch 69/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 147.0974 - reconstruction_loss: 140.6151 - kl_loss: 6.5259 - lr: 0.0010\n",
            "Epoch 70/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 146.9616 - reconstruction_loss: 140.5115 - kl_loss: 6.5246 - lr: 0.0010\n",
            "Epoch 71/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 146.8220 - reconstruction_loss: 140.4860 - kl_loss: 6.5399 - lr: 0.0010\n",
            "Epoch 72/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 146.8159 - reconstruction_loss: 140.4698 - kl_loss: 6.5512 - lr: 0.0010\n",
            "Epoch 73/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 146.9716 - reconstruction_loss: 140.3731 - kl_loss: 6.5600 - lr: 0.0010\n",
            "Epoch 74/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 146.9835 - reconstruction_loss: 140.3419 - kl_loss: 6.5448 - lr: 0.0010\n",
            "Epoch 75/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 147.0898 - reconstruction_loss: 140.3682 - kl_loss: 6.5507 - lr: 0.0010\n",
            "Epoch 76/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 146.7049 - reconstruction_loss: 140.3100 - kl_loss: 6.5803 - lr: 0.0010\n",
            "Epoch 77/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 146.6809 - reconstruction_loss: 140.1974 - kl_loss: 6.5667 - lr: 0.0010\n",
            "Epoch 78/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 146.2749 - reconstruction_loss: 140.1793 - kl_loss: 6.5793 - lr: 0.0010\n",
            "Epoch 79/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 146.2367 - reconstruction_loss: 140.1230 - kl_loss: 6.5776 - lr: 0.0010\n",
            "Epoch 80/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 146.6298 - reconstruction_loss: 140.0241 - kl_loss: 6.5881 - lr: 0.0010\n",
            "Epoch 81/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 146.2156 - reconstruction_loss: 140.0238 - kl_loss: 6.5846 - lr: 0.0010\n",
            "Epoch 82/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 146.6177 - reconstruction_loss: 139.9482 - kl_loss: 6.5734 - lr: 0.0010\n",
            "Epoch 83/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 146.4843 - reconstruction_loss: 139.9192 - kl_loss: 6.5860 - lr: 0.0010\n",
            "Epoch 84/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 146.2518 - reconstruction_loss: 139.9323 - kl_loss: 6.5855 - lr: 0.0010\n",
            "Epoch 85/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 146.0523 - reconstruction_loss: 139.8929 - kl_loss: 6.5911 - lr: 0.0010\n",
            "Epoch 86/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 146.0022 - reconstruction_loss: 139.7681 - kl_loss: 6.5912 - lr: 0.0010\n",
            "Epoch 87/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 146.3072 - reconstruction_loss: 139.7891 - kl_loss: 6.5900 - lr: 0.0010\n",
            "Epoch 88/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 146.0286 - reconstruction_loss: 139.7981 - kl_loss: 6.5964 - lr: 0.0010\n",
            "Epoch 89/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 146.1289 - reconstruction_loss: 139.6537 - kl_loss: 6.5881 - lr: 0.0010\n",
            "Epoch 90/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 145.8650 - reconstruction_loss: 139.6622 - kl_loss: 6.6084 - lr: 0.0010\n",
            "Epoch 91/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 145.9333 - reconstruction_loss: 139.6182 - kl_loss: 6.6073 - lr: 0.0010\n",
            "Epoch 92/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 146.0325 - reconstruction_loss: 139.6009 - kl_loss: 6.6149 - lr: 0.0010\n",
            "Epoch 93/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 146.1129 - reconstruction_loss: 139.4904 - kl_loss: 6.6164 - lr: 0.0010\n",
            "Epoch 94/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 145.8954 - reconstruction_loss: 139.4689 - kl_loss: 6.5984 - lr: 0.0010\n",
            "Epoch 95/1000\n",
            "547/547 [==============================] - 11s 19ms/step - loss: 146.1032 - reconstruction_loss: 139.4976 - kl_loss: 6.6303 - lr: 0.0010\n",
            "Epoch 96/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 145.9977 - reconstruction_loss: 139.5082 - kl_loss: 6.6230 - lr: 0.0010\n",
            "Epoch 97/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 145.7419 - reconstruction_loss: 139.4947 - kl_loss: 6.6114 - lr: 0.0010\n",
            "Epoch 98/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 145.3096 - reconstruction_loss: 138.4415 - kl_loss: 6.6483 - lr: 5.0000e-04\n",
            "Epoch 99/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 144.8396 - reconstruction_loss: 138.3107 - kl_loss: 6.6696 - lr: 5.0000e-04\n",
            "Epoch 100/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 145.0316 - reconstruction_loss: 138.2636 - kl_loss: 6.6918 - lr: 5.0000e-04\n",
            "Epoch 101/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 144.5540 - reconstruction_loss: 138.2436 - kl_loss: 6.6929 - lr: 5.0000e-04\n",
            "Epoch 102/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 144.9099 - reconstruction_loss: 138.2383 - kl_loss: 6.6895 - lr: 5.0000e-04\n",
            "Epoch 103/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 144.7806 - reconstruction_loss: 138.1781 - kl_loss: 6.7069 - lr: 5.0000e-04\n",
            "Epoch 104/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 144.8951 - reconstruction_loss: 138.1283 - kl_loss: 6.6915 - lr: 5.0000e-04\n",
            "Epoch 105/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 144.5993 - reconstruction_loss: 138.0840 - kl_loss: 6.7038 - lr: 5.0000e-04\n",
            "Epoch 106/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 144.6282 - reconstruction_loss: 138.0909 - kl_loss: 6.7114 - lr: 5.0000e-04\n",
            "Epoch 107/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 145.1833 - reconstruction_loss: 138.0868 - kl_loss: 6.6929 - lr: 5.0000e-04\n",
            "Epoch 108/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 144.6178 - reconstruction_loss: 138.0207 - kl_loss: 6.6967 - lr: 5.0000e-04\n",
            "Epoch 109/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 144.6541 - reconstruction_loss: 138.0223 - kl_loss: 6.6966 - lr: 5.0000e-04\n",
            "Epoch 110/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 144.1678 - reconstruction_loss: 137.9642 - kl_loss: 6.7066 - lr: 5.0000e-04\n",
            "Epoch 111/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 144.5414 - reconstruction_loss: 137.9676 - kl_loss: 6.7110 - lr: 5.0000e-04\n",
            "Epoch 112/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 144.4362 - reconstruction_loss: 137.9471 - kl_loss: 6.7082 - lr: 5.0000e-04\n",
            "Epoch 113/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 144.2998 - reconstruction_loss: 137.9116 - kl_loss: 6.7232 - lr: 5.0000e-04\n",
            "Epoch 114/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 144.5085 - reconstruction_loss: 137.8770 - kl_loss: 6.7196 - lr: 5.0000e-04\n",
            "Epoch 115/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 144.3748 - reconstruction_loss: 137.8459 - kl_loss: 6.7097 - lr: 5.0000e-04\n",
            "Epoch 116/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 144.5102 - reconstruction_loss: 137.8354 - kl_loss: 6.7090 - lr: 5.0000e-04\n",
            "Epoch 117/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 144.1997 - reconstruction_loss: 137.8311 - kl_loss: 6.7284 - lr: 5.0000e-04\n",
            "Epoch 118/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 144.3139 - reconstruction_loss: 137.8616 - kl_loss: 6.7320 - lr: 5.0000e-04\n",
            "Epoch 119/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 144.3676 - reconstruction_loss: 137.7457 - kl_loss: 6.7178 - lr: 5.0000e-04\n",
            "Epoch 120/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 144.4904 - reconstruction_loss: 137.7671 - kl_loss: 6.7271 - lr: 5.0000e-04\n",
            "Epoch 121/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 144.3417 - reconstruction_loss: 137.7434 - kl_loss: 6.7383 - lr: 5.0000e-04\n",
            "Epoch 122/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 144.6579 - reconstruction_loss: 137.7458 - kl_loss: 6.7381 - lr: 5.0000e-04\n",
            "Epoch 123/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 144.4130 - reconstruction_loss: 137.2008 - kl_loss: 6.7565 - lr: 2.5000e-04\n",
            "Epoch 124/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 143.5681 - reconstruction_loss: 137.1160 - kl_loss: 6.7740 - lr: 2.5000e-04\n",
            "Epoch 125/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 143.5462 - reconstruction_loss: 137.0830 - kl_loss: 6.7633 - lr: 2.5000e-04\n",
            "Epoch 126/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 143.7871 - reconstruction_loss: 137.0759 - kl_loss: 6.7652 - lr: 2.5000e-04\n",
            "Epoch 127/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 143.8123 - reconstruction_loss: 137.0615 - kl_loss: 6.7631 - lr: 2.5000e-04\n",
            "Epoch 128/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 143.6943 - reconstruction_loss: 137.0367 - kl_loss: 6.7732 - lr: 2.5000e-04\n",
            "Epoch 129/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 143.3279 - reconstruction_loss: 137.0274 - kl_loss: 6.7685 - lr: 2.5000e-04\n",
            "Epoch 130/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 143.6311 - reconstruction_loss: 137.0570 - kl_loss: 6.7820 - lr: 2.5000e-04\n",
            "Epoch 131/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 143.3703 - reconstruction_loss: 136.9960 - kl_loss: 6.7851 - lr: 2.5000e-04\n",
            "Epoch 132/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 143.7244 - reconstruction_loss: 136.9874 - kl_loss: 6.7765 - lr: 2.5000e-04\n",
            "Epoch 133/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 143.7283 - reconstruction_loss: 136.9877 - kl_loss: 6.7784 - lr: 2.5000e-04\n",
            "Epoch 134/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 143.7877 - reconstruction_loss: 136.9893 - kl_loss: 6.7905 - lr: 2.5000e-04\n",
            "Epoch 135/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 143.8704 - reconstruction_loss: 136.9430 - kl_loss: 6.7933 - lr: 2.5000e-04\n",
            "Epoch 136/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 143.6478 - reconstruction_loss: 136.9278 - kl_loss: 6.7816 - lr: 2.5000e-04\n",
            "Epoch 137/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 143.7686 - reconstruction_loss: 136.9666 - kl_loss: 6.7977 - lr: 2.5000e-04\n",
            "Epoch 138/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 143.9674 - reconstruction_loss: 136.9037 - kl_loss: 6.7982 - lr: 2.5000e-04\n",
            "Epoch 139/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 143.6895 - reconstruction_loss: 136.9494 - kl_loss: 6.8066 - lr: 2.5000e-04\n",
            "Epoch 140/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 143.6681 - reconstruction_loss: 136.9057 - kl_loss: 6.7980 - lr: 2.5000e-04\n",
            "Epoch 141/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 143.6324 - reconstruction_loss: 136.8727 - kl_loss: 6.7891 - lr: 2.5000e-04\n",
            "Epoch 142/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 143.2190 - reconstruction_loss: 136.8691 - kl_loss: 6.8033 - lr: 2.5000e-04\n",
            "Epoch 143/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 143.3828 - reconstruction_loss: 136.8549 - kl_loss: 6.8055 - lr: 2.5000e-04\n",
            "Epoch 144/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 143.6776 - reconstruction_loss: 136.8557 - kl_loss: 6.8113 - lr: 2.5000e-04\n",
            "Epoch 145/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 143.4895 - reconstruction_loss: 136.8321 - kl_loss: 6.7885 - lr: 2.5000e-04\n",
            "Epoch 146/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 143.5172 - reconstruction_loss: 136.8198 - kl_loss: 6.8069 - lr: 2.5000e-04\n",
            "Epoch 147/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 143.7081 - reconstruction_loss: 136.8009 - kl_loss: 6.7952 - lr: 2.5000e-04\n",
            "Epoch 148/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 143.5147 - reconstruction_loss: 136.7934 - kl_loss: 6.7900 - lr: 2.5000e-04\n",
            "Epoch 149/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 143.6341 - reconstruction_loss: 136.7979 - kl_loss: 6.8051 - lr: 2.5000e-04\n",
            "Epoch 150/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 143.5258 - reconstruction_loss: 136.7969 - kl_loss: 6.8127 - lr: 2.5000e-04\n",
            "Epoch 151/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 143.3682 - reconstruction_loss: 136.7743 - kl_loss: 6.7932 - lr: 2.5000e-04\n",
            "Epoch 152/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 143.7225 - reconstruction_loss: 136.7618 - kl_loss: 6.8119 - lr: 2.5000e-04\n",
            "Epoch 153/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 143.4282 - reconstruction_loss: 136.7792 - kl_loss: 6.8215 - lr: 2.5000e-04\n",
            "Epoch 154/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 143.5940 - reconstruction_loss: 136.7423 - kl_loss: 6.8184 - lr: 2.5000e-04\n",
            "Epoch 155/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 143.5622 - reconstruction_loss: 136.7550 - kl_loss: 6.8139 - lr: 2.5000e-04\n",
            "Epoch 156/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 143.2838 - reconstruction_loss: 136.7220 - kl_loss: 6.8023 - lr: 2.5000e-04\n",
            "Epoch 157/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 143.2692 - reconstruction_loss: 136.7249 - kl_loss: 6.8096 - lr: 2.5000e-04\n",
            "Epoch 158/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 143.6074 - reconstruction_loss: 136.6834 - kl_loss: 6.8212 - lr: 2.5000e-04\n",
            "Epoch 159/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 143.4744 - reconstruction_loss: 136.6882 - kl_loss: 6.8359 - lr: 2.5000e-04\n",
            "Epoch 160/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 143.2417 - reconstruction_loss: 136.6814 - kl_loss: 6.8313 - lr: 2.5000e-04\n",
            "Epoch 161/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 143.7842 - reconstruction_loss: 136.6716 - kl_loss: 6.8213 - lr: 2.5000e-04\n",
            "Epoch 162/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 143.4546 - reconstruction_loss: 136.6970 - kl_loss: 6.8269 - lr: 2.5000e-04\n",
            "Epoch 163/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 143.2821 - reconstruction_loss: 136.6349 - kl_loss: 6.8268 - lr: 2.5000e-04\n",
            "Epoch 164/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 143.3615 - reconstruction_loss: 136.6420 - kl_loss: 6.8231 - lr: 2.5000e-04\n",
            "Epoch 165/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 143.2042 - reconstruction_loss: 136.6065 - kl_loss: 6.8198 - lr: 2.5000e-04\n",
            "Epoch 166/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 143.0103 - reconstruction_loss: 136.6471 - kl_loss: 6.8403 - lr: 2.5000e-04\n",
            "Epoch 167/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 143.2342 - reconstruction_loss: 136.5852 - kl_loss: 6.8230 - lr: 2.5000e-04\n",
            "Epoch 168/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 143.1907 - reconstruction_loss: 136.6135 - kl_loss: 6.8311 - lr: 2.5000e-04\n",
            "Epoch 169/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 143.5723 - reconstruction_loss: 136.5898 - kl_loss: 6.8310 - lr: 2.5000e-04\n",
            "Epoch 170/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 143.1299 - reconstruction_loss: 136.5638 - kl_loss: 6.8221 - lr: 2.5000e-04\n",
            "Epoch 171/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 143.8559 - reconstruction_loss: 136.5733 - kl_loss: 6.8269 - lr: 2.5000e-04\n",
            "Epoch 172/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 143.7511 - reconstruction_loss: 136.5660 - kl_loss: 6.8341 - lr: 2.5000e-04\n",
            "Epoch 173/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 143.4369 - reconstruction_loss: 136.5657 - kl_loss: 6.8271 - lr: 2.5000e-04\n",
            "Epoch 174/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 143.2002 - reconstruction_loss: 136.2497 - kl_loss: 6.8280 - lr: 1.2500e-04\n",
            "Epoch 175/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 143.1846 - reconstruction_loss: 136.2286 - kl_loss: 6.8422 - lr: 1.2500e-04\n",
            "Epoch 176/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 142.6590 - reconstruction_loss: 136.2064 - kl_loss: 6.8432 - lr: 1.2500e-04\n",
            "Epoch 177/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 142.9173 - reconstruction_loss: 136.2337 - kl_loss: 6.8464 - lr: 1.2500e-04\n",
            "Epoch 178/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 142.9485 - reconstruction_loss: 136.2044 - kl_loss: 6.8540 - lr: 1.2500e-04\n",
            "Epoch 179/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 142.9230 - reconstruction_loss: 136.2026 - kl_loss: 6.8552 - lr: 1.2500e-04\n",
            "Epoch 180/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 142.8225 - reconstruction_loss: 136.0315 - kl_loss: 6.8628 - lr: 6.2500e-05\n",
            "Epoch 181/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 142.6861 - reconstruction_loss: 136.0186 - kl_loss: 6.8594 - lr: 6.2500e-05\n",
            "Epoch 182/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 143.1117 - reconstruction_loss: 136.0169 - kl_loss: 6.8655 - lr: 6.2500e-05\n",
            "Epoch 183/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 142.8728 - reconstruction_loss: 135.9930 - kl_loss: 6.8664 - lr: 6.2500e-05\n",
            "Epoch 184/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 142.5954 - reconstruction_loss: 135.9731 - kl_loss: 6.8630 - lr: 6.2500e-05\n",
            "Epoch 185/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 142.4932 - reconstruction_loss: 135.9917 - kl_loss: 6.8587 - lr: 6.2500e-05\n",
            "Epoch 186/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 142.7854 - reconstruction_loss: 136.0017 - kl_loss: 6.8739 - lr: 6.2500e-05\n",
            "Epoch 187/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 143.2251 - reconstruction_loss: 135.9961 - kl_loss: 6.8776 - lr: 6.2500e-05\n",
            "Epoch 188/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 142.7968 - reconstruction_loss: 135.9179 - kl_loss: 6.8766 - lr: 3.1250e-05\n",
            "Epoch 189/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 142.7360 - reconstruction_loss: 135.8791 - kl_loss: 6.8721 - lr: 3.1250e-05\n",
            "Epoch 190/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 142.6612 - reconstruction_loss: 135.9102 - kl_loss: 6.8737 - lr: 3.1250e-05\n",
            "Epoch 191/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 142.6068 - reconstruction_loss: 135.8984 - kl_loss: 6.8801 - lr: 3.1250e-05\n",
            "Epoch 192/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 142.8514 - reconstruction_loss: 135.8768 - kl_loss: 6.8838 - lr: 3.1250e-05\n",
            "Epoch 193/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 142.6286 - reconstruction_loss: 135.8654 - kl_loss: 6.8835 - lr: 1.5625e-05\n",
            "Epoch 194/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 142.9902 - reconstruction_loss: 135.8382 - kl_loss: 6.8830 - lr: 1.5625e-05\n",
            "Epoch 195/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 142.6165 - reconstruction_loss: 135.8343 - kl_loss: 6.8854 - lr: 1.5625e-05\n",
            "Epoch 196/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 142.7690 - reconstruction_loss: 135.8356 - kl_loss: 6.8867 - lr: 1.5625e-05\n",
            "Epoch 197/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 142.3452 - reconstruction_loss: 135.8219 - kl_loss: 6.8835 - lr: 1.5625e-05\n",
            "Epoch 198/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 142.7861 - reconstruction_loss: 135.8537 - kl_loss: 6.8843 - lr: 1.5625e-05\n",
            "Epoch 199/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 142.6393 - reconstruction_loss: 135.8192 - kl_loss: 6.8841 - lr: 1.5625e-05\n",
            "Epoch 200/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 142.9472 - reconstruction_loss: 135.8300 - kl_loss: 6.8846 - lr: 1.5625e-05\n",
            "Epoch 201/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 143.0454 - reconstruction_loss: 135.8273 - kl_loss: 6.8831 - lr: 1.5625e-05\n",
            "Epoch 202/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 142.5786 - reconstruction_loss: 135.8127 - kl_loss: 6.8836 - lr: 1.5625e-05\n",
            "Epoch 203/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 142.6580 - reconstruction_loss: 135.8168 - kl_loss: 6.8795 - lr: 1.5625e-05\n",
            "Epoch 204/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 142.1741 - reconstruction_loss: 135.8378 - kl_loss: 6.8810 - lr: 1.5625e-05\n",
            "Epoch 205/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 142.5076 - reconstruction_loss: 135.8112 - kl_loss: 6.8802 - lr: 1.5625e-05\n",
            "Epoch 206/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 142.8854 - reconstruction_loss: 135.8203 - kl_loss: 6.8786 - lr: 1.5625e-05\n",
            "Epoch 207/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 142.6729 - reconstruction_loss: 135.8122 - kl_loss: 6.8801 - lr: 1.5625e-05\n",
            "Epoch 208/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 142.6899 - reconstruction_loss: 135.8209 - kl_loss: 6.8780 - lr: 1.5625e-05\n",
            "Epoch 209/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 142.6946 - reconstruction_loss: 135.8284 - kl_loss: 6.8834 - lr: 1.0000e-05\n",
            "Epoch 210/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 142.6760 - reconstruction_loss: 135.8101 - kl_loss: 6.8836 - lr: 1.0000e-05\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f26c2f2e5d0>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "\n",
        "#Train data\n",
        "x_train = np.expand_dims(x_train, -1).astype(\"float32\") / 255\n",
        "z_mean_train, _, _ = vae.encoder.predict(x_train)\n",
        "\n",
        "#Test data\n",
        "x_test = np.expand_dims(x_test, -1).astype(\"float32\") / 255\n",
        "z_mean_test, _, _ = vae.encoder.predict(x_test)\n",
        "\n",
        "z_mean_train.shape\n",
        "\n"
      ],
      "metadata": {
        "id": "c0UhR8QlJ-UK",
        "outputId": "e24a43d2-124a-44c4-e5a3-857257c3c93a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model=keras.models.Sequential()\n",
        "model.add(keras.Input(shape=z_mean_train.shape[1:]))\n",
        "model.add(keras.layers.Dense(30,activation='relu'))\n",
        "model.add(keras.layers.Dense(10,activation='softmax'))"
      ],
      "metadata": {
        "id": "rZ2d5knMK93J"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks=[tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', #val_loss\n",
        "                                                factor=0.5,\n",
        "                                                patience=3,\n",
        "                                                min_lr=1e-5),\n",
        "           tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
        "                                            patience=5),\n",
        "           tf.keras.callbacks.ModelCheckpoint(filepath='my_model.h5',\n",
        "                                              monitor='val_loss',\n",
        "                                              save_best_only=True)]"
      ],
      "metadata": {
        "id": "hx8Miq7CdqQP"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=keras.losses.SparseCategoricalCrossentropy(),\n",
        "              optimizer=keras.optimizers.Adam(lr=0.001),\n",
        "              metrics=[keras.metrics.SparseCategoricalAccuracy()]) # "
      ],
      "metadata": {
        "id": "GgSDLEghN5B_",
        "outputId": "4077786f-c093-4534-c822-46162bef9750",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history=model.fit(x=z_mean_train,y=y_train,\n",
        "          epochs=100,\n",
        "          batch_size=32,\n",
        "          validation_data=(z_mean_test,y_test),\n",
        "          callbacks=callbacks) #"
      ],
      "metadata": {
        "id": "0KB0PqkKOLF8",
        "outputId": "9b0aad02-a3f4-4f45-bc0f-f59ddb912949",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 1.2055 - sparse_categorical_accuracy: 0.5864 - val_loss: 0.9195 - val_sparse_categorical_accuracy: 0.7040 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.9002 - sparse_categorical_accuracy: 0.7141 - val_loss: 0.8269 - val_sparse_categorical_accuracy: 0.7390 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.8402 - sparse_categorical_accuracy: 0.7331 - val_loss: 0.7885 - val_sparse_categorical_accuracy: 0.7560 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.8085 - sparse_categorical_accuracy: 0.7436 - val_loss: 0.7647 - val_sparse_categorical_accuracy: 0.7582 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.7885 - sparse_categorical_accuracy: 0.7492 - val_loss: 0.7461 - val_sparse_categorical_accuracy: 0.7649 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.7728 - sparse_categorical_accuracy: 0.7520 - val_loss: 0.7356 - val_sparse_categorical_accuracy: 0.7572 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 0.7608 - sparse_categorical_accuracy: 0.7551 - val_loss: 0.7245 - val_sparse_categorical_accuracy: 0.7644 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 0.7514 - sparse_categorical_accuracy: 0.7565 - val_loss: 0.7160 - val_sparse_categorical_accuracy: 0.7690 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.7440 - sparse_categorical_accuracy: 0.7583 - val_loss: 0.7084 - val_sparse_categorical_accuracy: 0.7702 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.7378 - sparse_categorical_accuracy: 0.7585 - val_loss: 0.7052 - val_sparse_categorical_accuracy: 0.7723 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.7323 - sparse_categorical_accuracy: 0.7597 - val_loss: 0.6987 - val_sparse_categorical_accuracy: 0.7711 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.7271 - sparse_categorical_accuracy: 0.7609 - val_loss: 0.6961 - val_sparse_categorical_accuracy: 0.7701 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.7232 - sparse_categorical_accuracy: 0.7621 - val_loss: 0.6912 - val_sparse_categorical_accuracy: 0.7710 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.7198 - sparse_categorical_accuracy: 0.7618 - val_loss: 0.6933 - val_sparse_categorical_accuracy: 0.7714 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.7162 - sparse_categorical_accuracy: 0.7626 - val_loss: 0.6884 - val_sparse_categorical_accuracy: 0.7729 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.7134 - sparse_categorical_accuracy: 0.7628 - val_loss: 0.6879 - val_sparse_categorical_accuracy: 0.7749 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.7107 - sparse_categorical_accuracy: 0.7631 - val_loss: 0.6869 - val_sparse_categorical_accuracy: 0.7729 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.7078 - sparse_categorical_accuracy: 0.7635 - val_loss: 0.6847 - val_sparse_categorical_accuracy: 0.7751 - lr: 0.0010\n",
            "Epoch 19/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.7061 - sparse_categorical_accuracy: 0.7633 - val_loss: 0.6793 - val_sparse_categorical_accuracy: 0.7769 - lr: 0.0010\n",
            "Epoch 20/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.7042 - sparse_categorical_accuracy: 0.7641 - val_loss: 0.6836 - val_sparse_categorical_accuracy: 0.7667 - lr: 0.0010\n",
            "Epoch 21/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.7023 - sparse_categorical_accuracy: 0.7632 - val_loss: 0.6777 - val_sparse_categorical_accuracy: 0.7710 - lr: 0.0010\n",
            "Epoch 22/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.7004 - sparse_categorical_accuracy: 0.7646 - val_loss: 0.6786 - val_sparse_categorical_accuracy: 0.7707 - lr: 0.0010\n",
            "Epoch 23/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.6988 - sparse_categorical_accuracy: 0.7638 - val_loss: 0.6744 - val_sparse_categorical_accuracy: 0.7733 - lr: 0.0010\n",
            "Epoch 24/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.6969 - sparse_categorical_accuracy: 0.7638 - val_loss: 0.6766 - val_sparse_categorical_accuracy: 0.7742 - lr: 0.0010\n",
            "Epoch 25/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.6955 - sparse_categorical_accuracy: 0.7655 - val_loss: 0.6768 - val_sparse_categorical_accuracy: 0.7711 - lr: 0.0010\n",
            "Epoch 26/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.6947 - sparse_categorical_accuracy: 0.7646 - val_loss: 0.6725 - val_sparse_categorical_accuracy: 0.7770 - lr: 0.0010\n",
            "Epoch 27/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.6935 - sparse_categorical_accuracy: 0.7650 - val_loss: 0.6730 - val_sparse_categorical_accuracy: 0.7754 - lr: 0.0010\n",
            "Epoch 28/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.6926 - sparse_categorical_accuracy: 0.7640 - val_loss: 0.6732 - val_sparse_categorical_accuracy: 0.7704 - lr: 0.0010\n",
            "Epoch 29/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.6913 - sparse_categorical_accuracy: 0.7638 - val_loss: 0.6680 - val_sparse_categorical_accuracy: 0.7735 - lr: 0.0010\n",
            "Epoch 30/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.6901 - sparse_categorical_accuracy: 0.7648 - val_loss: 0.6682 - val_sparse_categorical_accuracy: 0.7746 - lr: 0.0010\n",
            "Epoch 31/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.6891 - sparse_categorical_accuracy: 0.7656 - val_loss: 0.6803 - val_sparse_categorical_accuracy: 0.7651 - lr: 0.0010\n",
            "Epoch 32/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.6884 - sparse_categorical_accuracy: 0.7647 - val_loss: 0.6669 - val_sparse_categorical_accuracy: 0.7757 - lr: 0.0010\n",
            "Epoch 33/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.6876 - sparse_categorical_accuracy: 0.7654 - val_loss: 0.6653 - val_sparse_categorical_accuracy: 0.7733 - lr: 0.0010\n",
            "Epoch 34/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.6868 - sparse_categorical_accuracy: 0.7650 - val_loss: 0.6677 - val_sparse_categorical_accuracy: 0.7735 - lr: 0.0010\n",
            "Epoch 35/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.6861 - sparse_categorical_accuracy: 0.7656 - val_loss: 0.6680 - val_sparse_categorical_accuracy: 0.7735 - lr: 0.0010\n",
            "Epoch 36/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.6854 - sparse_categorical_accuracy: 0.7666 - val_loss: 0.6659 - val_sparse_categorical_accuracy: 0.7723 - lr: 0.0010\n",
            "Epoch 37/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.6826 - sparse_categorical_accuracy: 0.7669 - val_loss: 0.6622 - val_sparse_categorical_accuracy: 0.7773 - lr: 5.0000e-04\n",
            "Epoch 38/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.6819 - sparse_categorical_accuracy: 0.7674 - val_loss: 0.6632 - val_sparse_categorical_accuracy: 0.7765 - lr: 5.0000e-04\n",
            "Epoch 39/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.6818 - sparse_categorical_accuracy: 0.7677 - val_loss: 0.6614 - val_sparse_categorical_accuracy: 0.7765 - lr: 5.0000e-04\n",
            "Epoch 40/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.6814 - sparse_categorical_accuracy: 0.7674 - val_loss: 0.6619 - val_sparse_categorical_accuracy: 0.7759 - lr: 5.0000e-04\n",
            "Epoch 41/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.6810 - sparse_categorical_accuracy: 0.7666 - val_loss: 0.6608 - val_sparse_categorical_accuracy: 0.7763 - lr: 5.0000e-04\n",
            "Epoch 42/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.6806 - sparse_categorical_accuracy: 0.7674 - val_loss: 0.6631 - val_sparse_categorical_accuracy: 0.7739 - lr: 5.0000e-04\n",
            "Epoch 43/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.6804 - sparse_categorical_accuracy: 0.7679 - val_loss: 0.6625 - val_sparse_categorical_accuracy: 0.7748 - lr: 5.0000e-04\n",
            "Epoch 44/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.6801 - sparse_categorical_accuracy: 0.7671 - val_loss: 0.6627 - val_sparse_categorical_accuracy: 0.7745 - lr: 5.0000e-04\n",
            "Epoch 45/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.6788 - sparse_categorical_accuracy: 0.7677 - val_loss: 0.6597 - val_sparse_categorical_accuracy: 0.7768 - lr: 2.5000e-04\n",
            "Epoch 46/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.6786 - sparse_categorical_accuracy: 0.7680 - val_loss: 0.6600 - val_sparse_categorical_accuracy: 0.7767 - lr: 2.5000e-04\n",
            "Epoch 47/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.6783 - sparse_categorical_accuracy: 0.7676 - val_loss: 0.6596 - val_sparse_categorical_accuracy: 0.7788 - lr: 2.5000e-04\n",
            "Epoch 48/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.6782 - sparse_categorical_accuracy: 0.7674 - val_loss: 0.6594 - val_sparse_categorical_accuracy: 0.7784 - lr: 2.5000e-04\n",
            "Epoch 49/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.6780 - sparse_categorical_accuracy: 0.7673 - val_loss: 0.6587 - val_sparse_categorical_accuracy: 0.7774 - lr: 2.5000e-04\n",
            "Epoch 50/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.6778 - sparse_categorical_accuracy: 0.7676 - val_loss: 0.6602 - val_sparse_categorical_accuracy: 0.7751 - lr: 2.5000e-04\n",
            "Epoch 51/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.6776 - sparse_categorical_accuracy: 0.7683 - val_loss: 0.6597 - val_sparse_categorical_accuracy: 0.7764 - lr: 2.5000e-04\n",
            "Epoch 52/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.6777 - sparse_categorical_accuracy: 0.7677 - val_loss: 0.6597 - val_sparse_categorical_accuracy: 0.7772 - lr: 2.5000e-04\n",
            "Epoch 53/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.6770 - sparse_categorical_accuracy: 0.7682 - val_loss: 0.6587 - val_sparse_categorical_accuracy: 0.7763 - lr: 1.2500e-04\n",
            "Epoch 54/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.6769 - sparse_categorical_accuracy: 0.7684 - val_loss: 0.6583 - val_sparse_categorical_accuracy: 0.7779 - lr: 1.2500e-04\n",
            "Epoch 55/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.6768 - sparse_categorical_accuracy: 0.7683 - val_loss: 0.6587 - val_sparse_categorical_accuracy: 0.7764 - lr: 1.2500e-04\n",
            "Epoch 56/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.6767 - sparse_categorical_accuracy: 0.7681 - val_loss: 0.6587 - val_sparse_categorical_accuracy: 0.7754 - lr: 1.2500e-04\n",
            "Epoch 57/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.6767 - sparse_categorical_accuracy: 0.7682 - val_loss: 0.6587 - val_sparse_categorical_accuracy: 0.7760 - lr: 1.2500e-04\n",
            "Epoch 58/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.6762 - sparse_categorical_accuracy: 0.7685 - val_loss: 0.6582 - val_sparse_categorical_accuracy: 0.7777 - lr: 6.2500e-05\n",
            "Epoch 59/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.6762 - sparse_categorical_accuracy: 0.7683 - val_loss: 0.6581 - val_sparse_categorical_accuracy: 0.7775 - lr: 6.2500e-05\n",
            "Epoch 60/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.6762 - sparse_categorical_accuracy: 0.7689 - val_loss: 0.6579 - val_sparse_categorical_accuracy: 0.7768 - lr: 6.2500e-05\n",
            "Epoch 61/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.6761 - sparse_categorical_accuracy: 0.7685 - val_loss: 0.6585 - val_sparse_categorical_accuracy: 0.7766 - lr: 6.2500e-05\n",
            "Epoch 62/100\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 0.6761 - sparse_categorical_accuracy: 0.7683 - val_loss: 0.6579 - val_sparse_categorical_accuracy: 0.7774 - lr: 6.2500e-05\n",
            "Epoch 63/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.6760 - sparse_categorical_accuracy: 0.7686 - val_loss: 0.6577 - val_sparse_categorical_accuracy: 0.7767 - lr: 6.2500e-05\n",
            "Epoch 64/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.6760 - sparse_categorical_accuracy: 0.7688 - val_loss: 0.6579 - val_sparse_categorical_accuracy: 0.7760 - lr: 6.2500e-05\n",
            "Epoch 65/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.6760 - sparse_categorical_accuracy: 0.7685 - val_loss: 0.6576 - val_sparse_categorical_accuracy: 0.7770 - lr: 6.2500e-05\n",
            "Epoch 66/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.6759 - sparse_categorical_accuracy: 0.7685 - val_loss: 0.6583 - val_sparse_categorical_accuracy: 0.7772 - lr: 6.2500e-05\n",
            "Epoch 67/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.6760 - sparse_categorical_accuracy: 0.7685 - val_loss: 0.6582 - val_sparse_categorical_accuracy: 0.7768 - lr: 6.2500e-05\n",
            "Epoch 68/100\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 0.6759 - sparse_categorical_accuracy: 0.7685 - val_loss: 0.6579 - val_sparse_categorical_accuracy: 0.7773 - lr: 6.2500e-05\n",
            "Epoch 69/100\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 0.6757 - sparse_categorical_accuracy: 0.7687 - val_loss: 0.6578 - val_sparse_categorical_accuracy: 0.7768 - lr: 3.1250e-05\n",
            "Epoch 70/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.6757 - sparse_categorical_accuracy: 0.7685 - val_loss: 0.6576 - val_sparse_categorical_accuracy: 0.7770 - lr: 3.1250e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(history.history.keys())\n",
        "\n",
        "acc=history.history['sparse_categorical_accuracy']\n",
        "val_acc=history.history['sparse_categorical_accuracy']\n",
        "loss=history.history['loss']\n",
        "val_loss=history.history['val_loss']\n",
        "\n",
        "epochs=range(1,len(acc)+1)"
      ],
      "metadata": {
        "id": "sNwG_yN_SOx_",
        "outputId": "ef8ebf6d-3b0f-4bfa-ef97-67de492bbaa6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['loss', 'sparse_categorical_accuracy', 'val_loss', 'val_sparse_categorical_accuracy', 'lr'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(epochs,loss,'bo',label='Train loss')\n",
        "plt.plot(epochs,val_loss,'g',label='Validation loss')\n",
        "plt.title('Losses')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend();\n"
      ],
      "metadata": {
        "id": "w0EiAkCAeMsF",
        "outputId": "eea73612-7804-4cec-8f32-8480cbdd8f42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(epochs,acc,'bo',label='Train metric')\n",
        "plt.plot(epochs,val_acc,'g',label='Validation metric')\n",
        "plt.title('Metrics')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Metrics')\n",
        "plt.legend();"
      ],
      "metadata": {
        "id": "PmTxSV1xeU54",
        "outputId": "20ed6026-a63e-46d3-de8e-a35c0457bd3f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEWCAYAAABxMXBSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deZxU1bnv/8/TM808GZGWQcURGQRxIIN4ohKT45DjAHKPkJgQjCYxiSZ68Bhjwv15fnpDjl6PCYaI0VaiaAgmRNQ4xERFGm0QMAgCaiMKMkN30wPP/WPt6q6eq5ouuqC/79drv6pq7b1XPRvb/dRae++1zN0RERFJVEZ7ByAiIocWJQ4REUmKEoeIiCRFiUNERJKixCEiIklR4hARkaQocYikITP7DzP7TXvHIdIY03McIokzsw3AUcBR7v5pXPlbwAhgsLtvaGb/c4BH3L0gtZGKpI5aHCLJWw9MjH0ws1OB/Laq3Myy2qoukVRQ4hBJ3sPA1XGfJwO/i30ws1wzu9vMPjCzT8zsV2bWycw6A38BjjKzPdFylJndbmbzzOwRM9sFTInKHomr87Nm9qqZ7TCzD81sSlR+oZmtMrPdZrbRzG48KP8C0qEpcYgk73Wgm5mdZGaZwATgkbj1dwLHE7qujgP6A7e5+17gS8BH7t4lWj6K9rkYmAf0AArjv8zMBhISzr1A36je4mj1bOBb7t4VGAq80NYHK1KfmsQirRNrdbwMvANsjMoNmAoMc/dtAGb2v4FHgVuaqe81d58fvS8zs/h1VwHPu/tj0eet0QJQCZxsZsvcfTuw/YCOSiQBanGItM7DhBP6FOK6qQgtgnxgadSttAN4JipvzofNrDsaeK+Jdf8GXAi8b2Yvm9lZCcQuckCUOERawd3fJ1wkvxB4Km7Vp0AZcIq794iW7u7eJbZrU1U283UfAsc2EccSd78YOAKYDzyexGGItIoSh0jrXQOcG127iNkPPADMNLMjAMysv5ldEK3/BOhtZt2T+J5C4ItmdoWZZZlZbzMbYWY5ZjbJzLq7eyWwK/p+kZRS4hBpJXd/z92LGln1Y2At8Hp0l9TzwAnRPv8EHgPWRV1ZRyXwPR8QWjY/BLYRLowPj1b/O7Ah+p5pwKQDOyqRlukBQBERSYpaHCIikhQlDhERSYoSh4iIJEWJQ0REkpLSJ8fNbDzw30Am8Bt3v7Pe+pnAuOhjPnCEu/cws3HAzLhNTwQmuPt8M5sDfAHYGa2b4u7FNKNPnz4+aNCgAz0cEZEOZenSpZ+6e4OHV1N2V1U0hs+7wHlACbAEmOjuq5rY/jvASHf/er3yXoRbGwvcvTRKHH9y93mJxjJ69GgvKmrsrkkREWmKmS1199H1y1PZVTUGWOvu69y9AphLGMitKRMJ97fXdxnwF3cvTUGMIiKSpFQmjv7UHX+nJCprIBr9czCNj+w5gYYJZYaZLTezmWaW2xbBiohIYtLl4vgEYJ67V8cXmlk/4FRgUVzxLYRrHqcDvQhP6TZgZlPNrMjMirZs2ZKaqEVEOqBUJo6NhFE9YwqoHXq6vsZaFQBXAH+IxuEBwN03ebAPeJDQJdaAu89y99HuPrpv35YGJhURkUSlMnEsAYaY2WAzyyEkhwX1NzKzE4GewGuN1NHgukfUCsHChAWXACvaOG4REWlGyhKHu1cB1xO6md4BHnf3lWZ2h5ldFLfpBGCu17u9y8wGEVosL9erutDM3gbeBvoAP0/NEYiIBIWFMGgQZGSE18LClvZIbT0Hq94mufthv4waNcpFpK5HHnEfONDdLLw+8khq9zvQehtbX7/s2muT36alfXr3ds/JcYfaJT+/berJzg7lB3JMidbbGkCRN3JO7RCj4+o5DjmUFBbC9OnwwQcwYABceCEsXFj7ecaMsF1L20ya1HS9vXrB7t1QUVG7Pj8fJk+uW0/9ei+8EB56CErjbo7PzoZu3WDbttbH21K9jcWbnQ1mdcvqS2SbwCGzEqqzyc62uvt02gp9/gl934HOm2H3UbDzaNh1dHit6tRojVk5VVinHVRmbofc3ZCzG3L2hPfV2VDWC8p6Q2lv2NcNzMnKqcYyqqmsqgYM9mfB/kzwTPAMcCMrOqbKyv2hrrwdtYsb7OsO5T2ipTtU5ZGfb8ya1fBvoiVNPcehxCHSjhpLEvVPoHVkVJHVZQeWv43KzB1Q0QVK+4ST0P7agSAaO5nX1uvQeQv02ADd3w8ns0+Gw+ah2P4c6pwSbD90+xC6lYQTU6cdkLsj7FPWG3b3gz39wsm0vAdU54QTXJwmT95Z5dD9AzhiRe3Saw3sPQK2DYGtQ2DbceG4erxfG2+3jeH7s0she294BdifHU7I+7OhKi/82+zrGl4rogkYMyshoyosOXsg/9PaJWtfOEnv6xpO5BVdQ6Lo3MJdmdXZUJkPlZ3Cq+2HTtshb2fz+x0s//M2bB7KwIGwYUNyuypxKHEcluqfeFv6pd3UNgfre5r81Z9dGp3AtoZfuJ22hpN1z/XhhNljfThhNncyKusJOwbCR6Nh45iwbD0+/FoueAOOWhKW3msgu6zh/lW58PFw+Hgk5O4M+/VZ3fi2zamOTtxVedEJNR8qOodf5jXH+SnkxE2c6AbbjwnJovPmEGPu7rr17s+MfukXhBN7Zefa+t0gsyJKDJUhKcV+3efsCYvHfsFnh9fK/JB0Y0t593CsubvCkrMbynvClpPg05PC654joetH0P3D2oSauyvsl10KWdG/VVmv2qW8Z5SIokRW2TnEmL8VOm0L/61zd0UtiszaFgYOGdUhyVl1SEh1WKgv1rrYF00qmbszaoFEr0XfgvKemMH+JOeHVOJQ4mhXqTjBFxbC1Kktd5vU/wWfn0+LzfZku3WS3iZ7Lwx8BY55PixHLms8kLIesGMQ7BgcTpilvWtPSPu6h3piJ+LOW8Iv9v5Lwi/e+kp7wUenw+ZTQp07B4bXyk7Q7y04qigkliOLQ/2fnghbTwivOwaFxBTrBqnoHE58XTaFE2nXTeHkl1UOmfvCa1Z51CooDUkiuzTsF3+y3tMPNg8NJ+XKznHBeu3x2P4Q6+6j6rSq2pMZHGqnTrU4kqTE0bZa6oNvbb94sn3nu/dWs63P0zBqVvgF9+FY+GAsbDwj/MLDw8mtW0k4wW07LiwYmZnh11djffA1J/iqKui9OpxUj3wL+r0Z6vp4BJScBSVnwqbTwonyiJW13S35n8Kez9R24ZT2Cd/fa23t8pm3w6/jqhz44LPw/udhd/8oMUT93rv7h5N00hx6vReSQJ/V4cS/cQxsHwxYk3slejJM1Ukz2Xrb9hpH8/sk8veabD1ted2mpXoT+bHUGCUOJY6EJJIUWvofpj4z8Lxt4eS7r3voDtmfXXej3u/CyU/AkIWhj3vTabXLnn51t+20FU6bDaf/T+j73lkQTrafWQ7msD8jnHQ7bw791vF2FsD6c8Oy6TSo7EyW52PVnaisIPzqHvAPGPB3KHgNcveE/Srz4JNhod4j34KeG0L5/szQnRCzr0uIv8sndbtiYttuHwzbjw11rftiSBqV+Q3/vZr537I1J8PG6m3NyTCRllZr4k2k3vrxJnqTQEvbJLJPIi3k1tTTWCu7NceUSL3JJg1Q4lDioA2SQuyiX+ePw4mxy6bQRRF7zais29+6PzN0wRxVFH4Bx1TmhX74kjNDy+Ckp6BfNDL+xtGhy6PPu7XbV+WG/umYzArI2A8bvgCLvwOrLw5dGLm7oOB1OPof4ft29wt3vuwqCC2AI1bA4BfC0vnTpv+h3MKJPdZ62XRa+NUe303S5ePwXf3fCMeweWhYdg6ovTicszv8u+RvCX3jOwc0TJj1JHJnU0snl0TvmGrtybAtTqCtqbe1Jz9pPSWODpg4Gu2n973hgmFZT6iOGx8yb3ttl8yRy0J3S+yOlZy94YJb582QWdXwiyo7hZN0dU7tBbnYBdWai7WnhxNwp+3hhFvwWuj6yaqAD8+ClVfAqn8LJ3oISeAzy+CopSExxavOhVWXhZN7Ahr8grf9IYn0+We4mJldFl4zK0NrqOTM2guNidbZym0a+xXdFidHnXSlLShxHOaJo9nbOnutgeP/DEP+DAP/Fk7WEE745T1Cy6B7SW1lu/qHvvnY3TCV+eFX9d7PhF/usdc9/ULC2NeNBn3nmRWh77+iK9DESTRzX0gQpX2b3qYFvXtDly6J/9LOyIDq6qbra0prr8m0tI1O6JLOmkoc7f5U98FYDvcnxx95JDzJWvPkaEaFM+hF54LvO985zrmdsFx3knPejc7p9zmfmxHeX3SNc+m/O2PvdI5d5ORvrvMEamOLWfPr6y/1n7JN5EncxrZprN5Eni5u9t8qesq2NU/eJvIEdaqeshY5GGjiyfF2P6kfjOVQTxwtDbWQmelOp63O0Eedr17l/LhHSBS35jiTxjun/1+nx7qETvItJYVEhlpobIiERI6ppW0Sqbct/j11ghcJmkoc6qpKc3WeVcgqh5zdZOXvhdw9VGXuCF1PQxaGawYZ+2FvX3j3y7D6Ilh3Xu0TswlI9MKsulZEOoamuqrS42kaqSP+eoVlOPsHPQtn/x849jkAGlye/mgU/O1WWHNhuBDtmUB0zSBus0TGFFJSEJGWKHGkgUbvfqreB8Mfw8/6RXhYbHc/eOWWcNG6onPt+Dsfjwy3etaT6O2XIiLJUuJoZ3W6ojKq2Nr9RTj78fBsQ/42+ORU+MMcWDEx3O7ajPpPQytJiEgqKHG0s+nTodQ+ga/8BE6eF4bI2NclPNS27Gp47zzq3+ra2JO4rR1SQEQkWUoc7ex9/gbTJoRRMt/5angQbu0FDcb4b25sJbUwRORgUuI4yGLXM97/YD89vnwXTJ4ehpN+5Jkmn4RuqjWhRCEi7UGJ4yCquZ7h22DCZHac8Cds1eVkLfwNlXu61Wynp4tFJJ1ltLxJ65nZeDNbbWZrzezmRtbPNLPiaHnXzHbErauOW7cgrnywmS2O6vy9mTV/xTiNTJ8Opf2ehWuHwXGLYOE9+OO/p1tuNwYODNctBg6EBx+ETz8NXVMbNihpiEh6SVmLw8wygfuA84ASYImZLXD3VbFt3P37cdt/BxgZV0WZu49opOr/Ama6+1wz+xVwDXB/Ko6hLdR0TW3aC+fdBKffD1tOhLnzwzMXhJbFp80M1ioikk5S2eIYA6x193XuXgHMBS5uZvuJwGPNVWhmBpwLzIuKHgIuaYNYUyLWNfX+/n/AtOEw+lfw6g/g12/WJA0I3VEiIoeKVCaO/sCHcZ9LorIGzGwgMBh4Ia44z8yKzOx1M4slh97ADnePPTzdXJ1To/2LtmxpYbL5FJk+HUp7LoYp54Q5g+e8CM/+nzp3TOXn194lJSJyKEiXi+MTgHnuHj/g9UB332hmxwAvmNnbwM5EK3T3WcAsCGNVtWm0CXr/k53wrYlh1rhZS8M8zhEzXfgWkUNTKhPHRuDouM8FUVljJgDXxRe4+8bodZ2ZvUS4/vEk0MPMsqJWR3N1tit3J/+KaZR2/wAe/FudpNGaSeNFRNJFKruqlgBDorugcgjJYUH9jczsRKAn8FpcWU8zy43e9wHGAquiYX5fBC6LNp0M/DGFx9BqDy17iNJj5pL995/Ch2fXlKtrSkQOdSlLHFGL4HpgEfAO8Li7rzSzO8zsorhNJwBzve747icBRWa2jJAo7oy7G+vHwA/MbC3hmsfsVB1DsgoLYdAgsL6r+fq86zip0znM/trNdW611bAgInKo03wcbaTm4b59++AbZ0L3D8mbs4zf/KK/EoWIHJKamo8jpQ8AdiTTp0cj3J75S+hXDPMfpHxzf6ZPb+/IRETalhJHG/ngA8D2w6hZsH4cvPuvteUiIocRJY42MmAAMPBl6LUO3rymbrmIyGFEiaONzJgBmWN+A+Xdw/Do6A4qETk8KXG0kQu/up2MU56ky/pJWHUn3UElIoetdHly/JD36NuPUun7WDzzG4yc297RiIikjlocbWT2W7MZeeRIRvYb2fLGIiKHMCWONvDmpjd56+O3uGbkNS1vLCJyiFPiaAOz35xNXlYeV516VXuHIiKSckocB6CwEAYcW8b//L2QzNX/xsKnerZ3SCIiKaeL461UM8TIsU9B3k72vnINU58M63QnlYgcztTiaKWaIUZOmw3bjoH3v0BpKRpiREQOe0ocrfTBB0BWGQx4BVZdDp5RWy4ichhT4milAQOAI4shswpKzqxbLiJyGFPiaKUZMyB78OLwoeQMQEOMiEjHoMTRSpMmwaiLF5O5twDb209DjIhIh6G7qg7A5uw3uGT0Gczb396RiIgcPGpxtNKWvVtYt30dZ/Q/o71DERE5qFKaOMxsvJmtNrO1ZnZzI+tnmllxtLxrZjui8hFm9pqZrTSz5WZ2Zdw+c8xsfdx+I1J5DE15Y+MbAJxRoMQhIh1LyrqqzCwTuA84DygBlpjZAndfFdvG3b8ft/13gNgIgaXA1e6+xsyOApaa2SJ33xGtv8nd56Uq9kQs3riYDMvgtH6ntWcYIiIHXSpbHGOAte6+zt0rgLnAxc1sPxF4DMDd33X3NdH7j4DNQN8Uxpq0Nza+wdAjhtIlp0t7hyIiclClMnH0Bz6M+1wSlTVgZgOBwcALjawbA+QA78UVz4i6sGaaWW4TdU41syIzK9qyZUtrj6FR7s4bG9/Q9Q0R6ZDS5eL4BGCeu1fHF5pZP+Bh4GvuHrt36RbgROB0oBfw48YqdPdZ7j7a3Uf37du2jZU129awvXw7Y/qPadN6RUQOBalMHBuBo+M+F0RljZlA1E0VY2bdgD8D09399Vi5u2/yYB/wIKFL7KCquTCuFoeIdECpTBxLgCFmNtjMcgjJYUH9jczsRKAn8FpcWQ7wB+B39S+CR60QzMyAS4AVKTuCJiwuWUyXnC6c3Pfkg/3VIiLtLmV3Vbl7lZldDywCMoHfuvtKM7sDKHL3WBKZAMx1d4/b/Qrg80BvM5sSlU1x92Kg0Mz6AgYUA9NSdQxNWbxxMaOPGk1mRubB/moRkXaX0ifH3X0hsLBe2W31Pt/eyH6PAI80Uee5bRhi0vZV7aP442K+f+b3W95YROQwlC4Xxw8ZxR8XU7m/Ug/+iUiHpcSRpMUbw4i4ujAuIh2VEkeSFm9czFFdj6J/t0YfSREROewpcSSosBAGDYJHX3qD7SvOoLCwvSMSEWkfShwJKCyEqVPh/c1bofdayt49g6lTUfIQkQ5JiSMB06dDaSnQ761Q8NHplJaGchGRjkaJIwEffBC9yYsG593bt265iEgHosSRgAEDojdZ5eG1Kq9uuYhIB6LEkYAZMyA/nzqJIz8/lIuIdDRKHAmYNAlmzYKeR4TEUXBkHrNmhXIRkY4mpUOOHE4mTYJNg8u56TlYtTyPro3OAiIicvhTiyMJZZVlAHTK7tTOkYiItB8ljiSUV5WTaZlkZaihJiIdlxJHEsqrysnLymvvMERE2pUSRxKUOERElDiSosQhIqLEkZTyaiUOEREljiSUVZbpjioR6fBSmjjMbLyZrTaztWZ2cyPrZ5pZcbS8a2Y74tZNNrM10TI5rnyUmb0d1XmPmVkqjyGeuqpERFL4AKCZZQL3AecBJcASM1vg7qti27j79+O2/w4wMnrfC/gJMBpwYGm073bgfuCbwGLCfObjgb+k6jjiKXGIiKS2xTEGWOvu69y9ApgLXNzM9hOBx6L3FwDPufu2KFk8B4w3s35AN3d/3d0d+B1wSeoOoS4lDhGR1CaO/sCHcZ9LorIGzGwgMBh4oYV9+0fvE6lzqpkVmVnRli1bWnUA9SlxiIikz8XxCcA8d69uqwrdfZa7j3b30X379m2TOpU4RERSmzg2AkfHfS6Iyhozgdpuqub23Ri9T6TONldWVUanLN1VJSIdWyoTxxJgiJkNNrMcQnJYUH8jMzsR6Am8Fle8CDjfzHqaWU/gfGCRu28CdpnZmdHdVFcDf0zhMdShFoeISArvqnL3KjO7npAEMoHfuvtKM7sDKHL3WBKZAMyNLnbH9t1mZj8jJB+AO9x9W/T+28AcoBPhbqqDckcVKHGIiECK5+Nw94WEW2bjy26r9/n2Jvb9LfDbRsqLgKFtF2XilDhERNLn4njac3clDhERlDgSVlFdAaDEISIdnhJHgsqqotn/dFeViHRwCSUOM/uemXWzYLaZvWlm56c6uHRSXlUOqMUhIpJoi+Pr7r6LcFtsT+DfgTtTFlUaUuIQEQkSTRyxEWgvBB5295VxZR2CEoeISJBo4lhqZs8SEsciM+sK7E9dWOlHiUNEJEj0OY5rgBHAOncvNbPewNdSF1b6UeIQEQkSbXFcDLzn7rGJlqqBY1ITUnoqq4zuqtIMgCLSwSWaOH7i7jtjH6IE8pPUhJSe1OIQEQkSTRyNbZfS4UrSjRKHiEiQaOIoMrNfmNmx0fILYGkqA0s3ShwiIkGiieM7QAXw+2jZB1yXqqDSkRKHiEiQUHeTu+8Fbk5xLGlNiUNEJGg2cZjZL939BjN7GvD66939opRFlmY0VpWISNBSi+Ph6PXuVAeS7tTiEBEJmk0c7r7UzDKBqe4+6SDFlJZiiSMnM6edIxERaV8tXhx392pgYDRveIcVm8QpTHUuItJxJXpX1TrgH2b2n2b2g9jS0k5mNt7MVpvZWjNr9OK6mV1hZqvMbKWZPRqVjTOz4ril3MwuidbNMbP1cetGJHqwB0Kz/4mIBIk+xPdetGQAXaOyBhfL40VdXPcB5wElwBIzW+Duq+K2GQLcAox19+1mdgSAu79IGBsLM+sFrAWejav+Jnefl2DsbUKJQ0QkSDRxrHL3J+ILzOzyFvYZA6x193XR9nMJY16titvmm8B97r4dwN03N1LPZcBf3L00wVhToqyqTHdUiYiQeFfVLQmWxesPfBj3uSQqi3c8cLyZ/cPMXjez8Y3UMwF4rF7ZDDNbbmYzzSy3sS83s6lmVmRmRVu2bGkh1JapxSEiErT0HMeXCHNw9Deze+JWdQOq2uj7hwDnAAXA38zs1NgovGbWDzgVWBS3zy3Ax0AOMAv4MXBH/YrdfVa0ntGjRzfbrZYIJQ4RkaClFsdHQBFQThibKrYsAC5oYd+NwNFxnwuisnglwAJ3r3T39cC7hEQScwXwB3evjBW4+yYP9gEPErrEUk6JQ0QkaOk5jmXAsuhupyxggLuvTrDuJcAQMxtMSBgTgKvqbTMfmAg8aGZ9CF1X6+LWT6Rel5iZ9XP3TRbui70EWJFgPAdEiUNEJEj0Gsd4oBh4BsDMRpjZguZ2cPcq4HpCN9M7wOPuvtLM7jCz2FAli4CtZrYKeJFwt9TW6DsGEVosL9erutDM3gbeBvoAP0/wGA6IEoeISJDoXVW3E7qEXgJw9+KoJdEsd18ILKxXdlvcewd+EC31991Aw4vpuPu5CcbcpsoqyzT7n4gIibc4KuNnAIwc8AXnQ4laHCIiQaItjpVmdhWQGT20913g1dSFlX7Kq8rJy1TiEBFJZiKnUwgTOD0G7AJuSFVQ6UgtDhGRINGJnEqB6dHSISlxiIgELT0A2NKdUx1mIiclDhGRoKUWx1mEYUMeAxYDHXJM8ar9VVR7te6qEhGh5cRxJGF024mEh/f+DDzm7itTHVg6KasM08aqxSEi0sLFcXevdvdn3H0ycCZhePOXzOz6gxJdmtC0sSIitVq8OB6NPvtlQqtjEHAP8IfUhpVelDhERGq1dHH8d8BQwtPfP3X3gzIuVLpR4hARqdVSi+N/AXuB7wHfjZtv2wgjhnRLYWxpQ4lDRKRWS6PjJvqA4GEtljg0A6CISOJPjndoZVW6q0pEJEaJIwHqqhIRqaXEkQAlDhGRWkocCVDiEBGppcSRACUOEZFaShwJqLmrSmNViYikNnGY2XgzW21ma83s5ia2ucLMVpnZSjN7NK682syKo2VBXPlgM1sc1fl7M8tJ5TGAxqoSEYmXssRhZpnAfcCXgJOBiWZ2cr1thgC3AGPd/RTqTg5V5u4joiV++Pb/Ama6+3HAduCaVB1DjLqqRERqpbLFMQZY6+7r3L0CmAtcXG+bbwL3uft2AHff3FyFFh5dPxeYFxU9BFzSplE3IpY4cjNzU/1VIiJpL5WJoz9hLo+Ykqgs3vHA8Wb2DzN73czGx63LM7OiqDyWHHoDO9y9qpk6ATCzqdH+RVu2bDmgAymvKic7I5vMjMwDqkdE5HCQ0NSxKf7+IcA5QAHwNzM71d13AAPdfaOZHQO8YGZvAzsTrdjdZwGzAEaPHu0HEqRm/xMRqZXKFsdG4Oi4zwVRWbwSYIG7V7r7euBdQiLB3TdGr+uAl4CRwFagh5llNVNnmyuvKtcdVSIikVQmjiXAkOguqBxgAlB/DvP5hNYGZtaH0HW1zsx6RvOAxMrHAqvc3YEXgcui/ScDf0zhMQBhrCq1OEREgpQljug6xPXAIuAd4HF3X2lmd5hZ7C6pRcBWM1tFSAg3uftW4CSgyMyWReV3uvuqaJ8fAz8ws7WEax6zU3UMMeqqEhGpldJrHO6+kDAJVHzZbXHvHfhBtMRv8ypwahN1riPcsXXQKHGIiNTSk+MJUOIQEamlxJEAJQ4RkVpKHAkoryrX7H8iIhEljgTorioRkVpKHAlQV5WISC0ljgQocYiI1FLiSIASh4hILSWOBChxiIjUUuJIgO6qEhGppcTRgur91VRUV6jFISISUeJowb7qfYBm/xMRiVHiaIGmjRURqUuJowVKHCIidSlxtECJQ0SkLiWOFsQSh2YAFBEJlDhaUFZZBqjFISISo8TRAnVViYjUpcTRAiUOEZG6Upo4zGy8ma02s7VmdnMT21xhZqvMbKWZPRqVjTCz16Ky5WZ2Zdz2c8xsvZkVR8uIVB6DEoeISF0pm3PczDKB+4DzgBJgiZktcPdVcdsMAW4Bxrr7djM7IlpVClzt7mvM7ChgqZktcvcd0fqb3H1eqmKPp8QhIlJXKlscY4C17r7O3SuAucDF9bb5JnCfu28HcPfN0eu77r4mev8RsBnom8JYm1RzV5XGqhIRAVKbOPoDH8Z9LonK4h0PHG9m/zCz181sfP1KzGwMkAO8F1c8I+rCmmlmuY19uZlNNcxUEasAABP7SURBVLMiMyvasmVLqw+irEp3VYmIxGvvi+NZwBDgHGAi8ICZ9YitNLN+wMPA19x9f1R8C3AicDrQC/hxYxW7+yx3H+3uo/v2bX1jRV1VIiJ1pTJxbASOjvtcEJXFKwEWuHulu68H3iUkEsysG/BnYLq7vx7bwd03ebAPeJDQJZYyShwiInWlMnEsAYaY2WAzywEmAAvqbTOf0NrAzPoQuq7WRdv/Afhd/YvgUSsEMzPgEmBFCo9BiUNEpJ6U3VXl7lVmdj2wCMgEfuvuK83sDqDI3RdE6843s1VANeFuqa1m9r+AzwO9zWxKVOUUdy8GCs2sL2BAMTAtVccAIXFkWAZZGSn7pxIROaSk9Gzo7guBhfXKbot778APoiV+m0eAR5qo89y2j7Rpsdn/QgNHRETa++J42iurLFM3lYhIHCWOFpRXlStxiIjEUeJoQXm1EoeISDwljhaoxSEiUpcSRwuUOERE6lLiaEF5Vblm/xMRiaPE0QLdVSUiUpcSRwvUVSUiUpceh26BEocIVFZWUlJSQnl5eXuHIimQl5dHQUEB2dnZCW2vxNECJQ4RKCkpoWvXrgwaNEijKBxm3J2tW7dSUlLC4MGDE9pHXVUtKK8qJy9TiUM6tvLycnr37q2kcRgyM3r37p1Ua1KJowW6q0okUNI4fCX731aJowXqqhIRqUuJoxnuTlmVbscVSVZhIQwaBBkZ4bWw8MDq27p1KyNGjGDEiBEceeSR9O/fv+ZzRUVFs/sWFRXx3e9+98ACSMKGDRt49NFHm1z/0Ucfcdlllx20eFJBF8ebUVEd/iCVOEQSV1gIU6dCaWn4/P774TPApEmtq7N3794UFxcDcPvtt9OlSxduvPHGmvVVVVVkZTV+Ohs9ejSjR49u3Re3QixxXHXVVQ3WVVVVcdRRRzFv3rxG9jx0qMXRDM3+J5K86dNrk0ZMaWkob0tTpkxh2rRpnHHGGfzoRz/ijTfe4KyzzmLkyJGcffbZrF69GoCXXnqJr3zlK0BIOl//+tc555xzOOaYY7jnnnsarbtLly7cdNNNnHLKKXzxi1/kjTfeqNlnwYIwkWl1dTU33XQTp59+OsOGDePXv/41ADfffDOvvPIKI0aMYObMmcyZM4eLLrqIc889l3/5l39hw4YNDB06tKaOG2+8kaFDhzJs2DDuvffetv1HShG1OJqhxCGSvA8+SK78QJSUlPDqq6+SmZnJrl27eOWVV8jKyuL555/nP/7jP3jyyScb7PPPf/6TF198kd27d3PCCSdw7bXXNnh+Ye/evZx77rncddddXHrppdx6660899xzrFq1ismTJ3PRRRcxe/ZsunfvzpIlS9i3bx9jx47l/PPP58477+Tuu+/mT3/6EwBz5szhzTffZPny5fTq1YsNGzbUfM+sWbPYsGEDxcXFZGVlsW3btrb/R0oBJY5mxBJHpyzdVSWSqAEDQvdUY+Vt7fLLLyczMxOAnTt3MnnyZNasWYOZUVlZ2eg+X/7yl8nNzSU3N5cjjjiCTz75hIKCgjrb5OTkMH78eABOPfVUcnNzyc7O5tRTT6058T/77LMsX768pttp586drFmzhpycnAbfed5559GrV68G5c8//zzTpk2r6WZrbJt0lNKuKjMbb2arzWytmd3cxDZXmNkqM1tpZo/GlU82szXRMjmufJSZvR3VeY+l8B5BtThEkjdjBuTn1y3Lzw/lba1z58417//zP/+TcePGsWLFCp5++ukmn0vIzc2teZ+ZmUlVVVWDbbKzs2tuUc3IyKjZJyMjo2Z7d+fee++luLiY4uJi1q9fz/nnn99inIeDlCUOM8sE7gO+BJwMTDSzk+ttMwS4BRjr7qcAN0TlvYCfAGcAY4CfmFnPaLf7gW8CQ6JlfKqOoayqDFDiEEnGpEkwaxYMHAhm4XXWrNZfGE/Uzp076d+/PxC6h1Ltggsu4P77769p2bz77rvs3buXrl27snv37oTqOO+88/j1r39dk4wOla6qVLY4xgBr3X2du1cAc4GL623zTeA+d98O4O6bo/ILgOfcfVu07jlgvJn1A7q5++vu7sDvgEtSdQBqcYi0zqRJsGED7N8fXlOdNAB+9KMfccsttzBy5MhGWxFt7Rvf+AYnn3wyp512GkOHDuVb3/oWVVVVDBs2jMzMTIYPH87MmTNbrGPAgAEMGzaM4cOHN3sbbzqxcP5NQcVmlwHj3f0b0ed/B85w9+vjtpkPvAuMBTKB2939GTO7Echz959H2/0nUAa8BNzp7l+Myj8H/Njdv9LI908FpgIMGDBg1PuNdbq24KUNLzHuoXG8cPULjBs8Lun9RQ4X77zzDieddFJ7hyEp1Nh/YzNb6u4N7mVu79txswjdTecAE4EHzKxHW1Ts7rPcfbS7j+7bt2+r6qi5OK4hR0REaqQycWwEjo77XBCVxSsBFrh7pbuvJ7Q+hjSz78bofXN1thl1VYmINJTKxLEEGGJmg80sB5gALKi3zXxCawMz6wMcD6wDFgHnm1nP6KL4+cAid98E7DKzM6O7qa4G/piqA1DiEBFpKGXPcbh7lZldT0gCmcBv3X2lmd0BFLn7AmoTxCqgGrjJ3bcCmNnPCMkH4A53j91u8G1gDtAJ+Eu0pERZpe6qEhGpL6UPALr7QmBhvbLb4t478INoqb/vb4HfNlJeBAxt82AboRaHiEhD7X1xPK0pcYiINKTE0QwNOSKSHsaNG8eiRYvqlP3yl7/k2muvbXKfc845h6KiIgAuvPBCduzY0WCb22+/nbvvvrvZ754/fz6rVq2q+Xzbbbfx/PPPJxN+StSPq75f/epX/O53v0vJdytxNCOWOHIyG449IyIHz8SJE5k7d26dsrlz5zJx4sSE9l+4cCE9erTuTv/6J+g77riDL37xi62qqy01lziqqqqYNm0aV199dUq+W4McNiM2+5+mzBSpdcMzN1D8cXGb1jniyBH8cvwvm1x/2WWXceutt1JRUUFOTg4bNmzgo48+4nOf+xzXXnstS5YsoaysjMsuu4yf/vSnDfYfNGgQRUVF9OnThxkzZvDQQw9xxBFHcPTRRzNq1CgAHnjgAWbNmkVFRQXHHXccDz/8MMXFxSxYsICXX36Zn//85zz55JP87Gc/4ytf+QqXXXYZf/3rX7nxxhupqqri9NNP5/777yc3N5dBgwYxefJknn76aSorK3niiSc48cQT68Q0Z84c5s+fz969e1mzZg033ngjFRUVPPzww+Tm5rJw4UJ69erFe++9x3XXXceWLVvIz8/ngQceYNu2bQ3iuuaaaxgxYgR///vfmThxIrt3766Zt2Tt2rVMmzaNLVu2kJmZyRNPPMGxxx7b6v9eanE0Q7P/iaSHXr16MWbMGP7yl3AT5dy5c7niiiswM2bMmEFRURHLly/n5ZdfZvny5U3Ws3TpUubOnUtxcTELFy5kyZIlNeu++tWvsmTJEpYtW8ZJJ53E7NmzOfvss7nooou46667KC4urnOyLS8vZ8qUKfz+97/n7bffpqqqivvvv79mfZ8+fXjzzTe59tprm+wOW7FiBU899RRLlixh+vTp5Ofn89Zbb3HWWWfVdDNNnTqVe++9l6VLl3L33Xfz7W9/u8m4KioqKCoq4oc//GGd75k0aRLXXXcdy5Yt49VXX6Vfv35J/heoSy2OZmi+cZGGmmsZpFKsu+riiy9m7ty5zJ49G4DHH3+cWbNmUVVVxaZNm1i1ahXDhg1rtI5XXnmFSy+9lPxo+N6LLrqoZt2KFSu49dZb2bFjB3v27OGCCy5oNp7Vq1czePBgjj/+eAAmT57Mfffdxw033ACERAQwatQonnrqqUbrGDduHF27dqVr1650796df/3XfwXCUO7Lly9nz549vPrqq1x++eU1++zbt6/JmK688soGZbt372bjxo1ceumlAOTlHfg5TYmjCYWF8Ogz5eztncegQWFI6IMxUJuINO7iiy/m+9//Pm+++SalpaWMGjWK9evXc/fdd7NkyRJ69uzJlClTmhxOvSVTpkxh/vz5DB8+nDlz5vDSSy8dULyxodibGro9fhtofPj2/fv306NHj5ppc1tysIZvV1dVI2JzJu/dVw5VnWrmTC4sbO/IRDquLl26MG7cOL7+9a/XXBTftWsXnTt3pnv37nzyySc1XVlN+fznP8/8+fMpKytj9+7dPP300zXrdu/eTb9+/aisrKQw7n/2poZJP+GEE9iwYQNr164F4OGHH+YLX/hCWxxqjW7dujF48GCeeOIJIMwBsmzZsmbjqq9r164UFBQwf/58ILRYSuvP7ZskJY5G1MyZnFUOVaFZl4o5k0UkORMnTmTZsmU1iWP48OGMHDmSE088kauuuoqxY8c2u/9pp53GlVdeyfDhw/nSl77E6aefXrPuZz/7GWeccQZjx46tcyF7woQJ3HXXXYwcOZL33nuvpjwvL48HH3yQyy+/nFNPPZWMjAymTZvWxkcMhYWFzJ49m+HDh3PKKafwxz/+sdm4GvPwww9zzz33MGzYMM4++2w+/vjjA4opZcOqp5PRo0d77H7uRGRkgDvw2f8P8nbC83cCYVKa/ftTFKRIGtOw6oe/ZIZV1zWORtTMmfz3WxqUi4h0dOqqasTBnDNZRORQo8TRiPaaM1kknXWEbu2OKtn/tuqqasKkSUoUIjF5eXls3bqV3r17aySFw4y7s3Xr1qSe71DiEJEWFRQUUFJSwpYtW9o7FEmBvLw8CgoKWt4wosQhIi3Kzs5m8ODB7R2GpAld4xARkaQocYiISFKUOEREJCkd4slxM9sCvJ/g5n2AT1MYTltTvKmleFNL8abWgcY70N371i/sEIkjGWZW1Ngj9ulK8aaW4k0txZtaqYpXXVUiIpIUJQ4REUmKEkdDs9o7gCQp3tRSvKmleFMrJfHqGoeIiCRFLQ4REUmKEoeIiCRFiSNiZuPNbLWZrTWzm9s7nsaY2W/NbLOZrYgr62Vmz5nZmui1Z3vGGGNmR5vZi2a2ysxWmtn3ovJ0jTfPzN4ws2VRvD+Nygeb2eLo7+L3ZpbT3rHGM7NMM3vLzP4UfU73eDeY2dtmVmxmRVFZWv5NAJhZDzObZ2b/NLN3zOysdI3XzE6I/l1jyy4zuyEV8SpxEP7nA+4DvgScDEw0s5PbN6pGzQHG1yu7Gfiruw8B/hp9TgdVwA/d/WTgTOC66N80XePdB5zr7sOBEcB4MzsT+C9gprsfB2wHrmnHGBvzPeCduM/pHi/AOHcfEfd8Qbr+TQD8N/CMu58IDCf8W6dlvO6+Ovp3HQGMAkqBP5CKeN29wy/AWcCiuM+3ALe0d1xNxDoIWBH3eTXQL3rfD1jd3jE2EfcfgfMOhXiBfOBN4AzCU7dZjf2dtPcCFEQngnOBPwGWzvFGMW0A+tQrS8u/CaA7sJ7oJqJ0j7dejOcD/0hVvGpxBP2BD+M+l0Rlh4LPuPum6P3HwGfaM5jGmNkgYCSwmDSON+r2KQY2A88B7wE73L0q2iTd/i5+CfwI2B997k16xwvgwLNmttTMpkZl6fo3MRjYAjwYdQf+xsw6k77xxpsAPBa9b/N4lTgOIx5+UqTV/dVm1gV4ErjB3XfFr0u3eN292kMzvwAYA5zYziE1ycy+Amx296XtHUuSPuvupxG6ha8zs8/Hr0yzv4ks4DTgfncfCeylXjdPmsULQHRd6yLgifrr2ipeJY5gI3B03OeCqOxQ8ImZ9QOIXje3czw1zCybkDQK3f2pqDht441x9x3Ai4Sunh5mFpvwLJ3+LsYCF5nZBmAuobvqv0nfeAFw943R62ZC//sY0vdvogQocffF0ed5hESSrvHGfAl4090/iT63ebxKHMESYEh0R0oOoZm3oJ1jStQCYHL0fjLhWkK7szAx9WzgHXf/RdyqdI23r5n1iN53IlyPeYeQQC6LNkubeN39FncvcPdBhL/XF9x9EmkaL4CZdTazrrH3hH74FaTp34S7fwx8aGYnREX/AqwiTeONM5HabipIRbztfREnXRbgQuBdQr/29PaOp4kYHwM2AZWEX0PXEPq1/wqsAZ4HerV3nFGsnyU0iZcDxdFyYRrHOwx4K4p3BXBbVH4M8AawltD0z23vWBuJ/RzgT+kebxTbsmhZGfv/LF3/JqLYRgBF0d/FfKBnmsfbGdgKdI8ra/N4NeSIiIgkRV1VIiKSFCUOERFJihKHiIgkRYlDRESSosQhIiJJUeIQaSUzq643GmmbDXZnZoPiR0EWSSdZLW8iIk0o8zBEiUiHohaHSBuL5pz4/6N5J94ws+Oi8kFm9oKZLTezv5rZgKj8M2b2h2gukGVmdnZUVaaZPRDND/Js9EQ7ZvbdaJ6T5WY2t50OUzowJQ6R1utUr6vqyrh1O939VOD/EkaxBbgXeMjdhwGFwD1R+T3Ayx7mAjmN8FQ1wBDgPnc/BdgB/FtUfjMwMqpnWqoOTqQpenJcpJXMbI+7d2mkfANhUqh10UCPH7t7bzP7lDAvQmVUvsnd+5jZFqDA3ffF1TEIeM7D5DuY2Y+BbHf/uZk9A+whDIEx3933pPhQRepQi0MkNbyJ98nYF/e+mtprkl8mzFh5GrAkbjRckYNCiUMkNa6Me30tev8qYSRbgEnAK9H7vwLXQs1kUt2bqtTMMoCj3f1F4MeEWeoatHpEUkm/VERar1M0Y2DMM+4euyW3p5ktJ7QaJkZl3yHMJncTYWa5r0Xl3wNmmdk1hJbFtYRRkBuTCTwSJRcD7vEwf4jIQaNrHCJtLLrGMdrdP23vWERSQV1VIiKSFLU4REQkKWpxiIhIUpQ4REQkKUocIiKSFCUOERFJihKHiIgk5f8B60yGtNF3LLMAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}