{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "01-mnist-VAE_v3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOSwxRgalrrFG/5N4/JWAc3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PeterPirog/tf-autoencoders/blob/main/01_mnist_VAE_v4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://keras.io/examples/generative/vae/\n",
        "Latent vector length =3\n",
        "\n",
        "https://harvard-iacs.github.io/2019-CS109B/labs/lab10/VAE-solutions/"
      ],
      "metadata": {
        "id": "BYzxx-LJDxRh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "0MDe9j_fDpu7"
      },
      "outputs": [],
      "source": [
        "# Setup\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "EPOCHS=1000  # for vae training\n",
        "latent_dim = 3"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a sampling layer\n",
        "\n",
        "class Sampling(layers.Layer):\n",
        "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
        "\n",
        "    def call(self, inputs):\n",
        "        z_mean, z_log_var = inputs\n",
        "        batch = tf.shape(z_mean)[0]\n",
        "        dim = tf.shape(z_mean)[1]\n",
        "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
        "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n"
      ],
      "metadata": {
        "id": "azwMsEScD6fJ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the encoder\n",
        "\n",
        "encoder_inputs = keras.Input(shape=(28, 28, 1))\n",
        "x = layers.Conv2D(32, 3, activation=\"relu\", strides=2, padding=\"same\")(encoder_inputs)\n",
        "x = layers.Conv2D(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
        "x = layers.Flatten()(x)\n",
        "x = layers.Dense(16, activation=\"relu\")(x)\n",
        "z_mean = layers.Dense(latent_dim, name=\"z_mean\")(x)\n",
        "z_log_var = layers.Dense(latent_dim, name=\"z_log_var\")(x)\n",
        "z = Sampling()([z_mean, z_log_var])\n",
        "encoder = keras.Model(encoder_inputs, [z_mean, z_log_var, z], name=\"encoder\")\n",
        "encoder.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jLxM8eNaD-6a",
        "outputId": "4fecd4ce-f411-4b72-879c-683fa1b82f68"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"encoder\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 28, 28, 1)]  0           []                               \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 14, 14, 32)   320         ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 7, 7, 64)     18496       ['conv2d[0][0]']                 \n",
            "                                                                                                  \n",
            " flatten (Flatten)              (None, 3136)         0           ['conv2d_1[0][0]']               \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 16)           50192       ['flatten[0][0]']                \n",
            "                                                                                                  \n",
            " z_mean (Dense)                 (None, 3)            51          ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " z_log_var (Dense)              (None, 3)            51          ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " sampling (Sampling)            (None, 3)            0           ['z_mean[0][0]',                 \n",
            "                                                                  'z_log_var[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 69,110\n",
            "Trainable params: 69,110\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the decoder\n",
        "\n",
        "latent_inputs = keras.Input(shape=(latent_dim,))\n",
        "x = layers.Dense(7 * 7 * 64, activation=\"relu\")(latent_inputs)\n",
        "x = layers.Reshape((7, 7, 64))(x)\n",
        "x = layers.Conv2DTranspose(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
        "x = layers.Conv2DTranspose(32, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
        "decoder_outputs = layers.Conv2DTranspose(1, 3, activation=\"sigmoid\", padding=\"same\")(x)\n",
        "decoder = keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n",
        "decoder.summary()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7BKuO7GHEDpB",
        "outputId": "7fd0e1e5-7e9d-4281-a295-dd799c3697b7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"decoder\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 3)]               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 3136)              12544     \n",
            "                                                                 \n",
            " reshape (Reshape)           (None, 7, 7, 64)          0         \n",
            "                                                                 \n",
            " conv2d_transpose (Conv2DTra  (None, 14, 14, 64)       36928     \n",
            " nspose)                                                         \n",
            "                                                                 \n",
            " conv2d_transpose_1 (Conv2DT  (None, 28, 28, 32)       18464     \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " conv2d_transpose_2 (Conv2DT  (None, 28, 28, 1)        289       \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 68,225\n",
            "Trainable params: 68,225\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the VAE as a Model with a custom train_step\n",
        "\n",
        "class VAE(keras.Model):\n",
        "    def __init__(self, encoder, decoder, **kwargs):\n",
        "        super(VAE, self).__init__(**kwargs)\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
        "        self.reconstruction_loss_tracker = keras.metrics.Mean(\n",
        "            name=\"reconstruction_loss\"\n",
        "        )\n",
        "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [\n",
        "            self.total_loss_tracker,\n",
        "            self.reconstruction_loss_tracker,\n",
        "            self.kl_loss_tracker,\n",
        "        ]\n",
        "\n",
        "    def train_step(self, data):\n",
        "        with tf.GradientTape() as tape:\n",
        "            z_mean, z_log_var, z = self.encoder(data)\n",
        "            reconstruction = self.decoder(z)\n",
        "            reconstruction_loss = tf.reduce_mean(\n",
        "                tf.reduce_sum(\n",
        "                    keras.losses.binary_crossentropy(data, reconstruction), axis=(1, 2)\n",
        "                )\n",
        "            )\n",
        "            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
        "            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n",
        "            total_loss = reconstruction_loss + kl_loss\n",
        "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
        "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
        "        self.total_loss_tracker.update_state(total_loss)\n",
        "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
        "        self.kl_loss_tracker.update_state(kl_loss)\n",
        "        return {\n",
        "            \"loss\": self.total_loss_tracker.result(),\n",
        "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
        "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
        "        }\n",
        "\n"
      ],
      "metadata": {
        "id": "JL5qVupYEIEi"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks_vae=[tf.keras.callbacks.ReduceLROnPlateau(monitor='loss', \n",
        "                                                factor=0.5,\n",
        "                                                patience=3,\n",
        "                                                min_lr=1e-5),\n",
        "           tf.keras.callbacks.EarlyStopping(monitor='loss',\n",
        "                                            patience=5)]"
      ],
      "metadata": {
        "id": "Hh6ebn3aHXL5"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the VAE\n",
        "\n",
        "(x_train, _), (x_test, _) = keras.datasets.mnist.load_data()\n",
        "mnist_digits = np.concatenate([x_train, x_test], axis=0)\n",
        "mnist_digits = np.expand_dims(mnist_digits, -1).astype(\"float32\") / 255\n",
        "\n",
        "vae = VAE(encoder, decoder)\n",
        "vae.compile(optimizer=keras.optimizers.Adam())\n",
        "vae.fit(mnist_digits, epochs=EPOCHS, batch_size=128,callbacks=callbacks_vae)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DCe0H3MSEPsa",
        "outputId": "e848d41e-32b1-487e-f976-cb5f46cf5cf3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "547/547 [==============================] - 13s 19ms/step - loss: 261.9246 - reconstruction_loss: 210.4452 - kl_loss: 2.8956 - lr: 0.0010\n",
            "Epoch 2/1000\n",
            "547/547 [==============================] - 10s 18ms/step - loss: 176.8220 - reconstruction_loss: 167.2564 - kl_loss: 6.1619 - lr: 0.0010\n",
            "Epoch 3/1000\n",
            "547/547 [==============================] - 10s 18ms/step - loss: 166.9757 - reconstruction_loss: 158.8683 - kl_loss: 6.3965 - lr: 0.0010\n",
            "Epoch 4/1000\n",
            "547/547 [==============================] - 10s 18ms/step - loss: 162.2949 - reconstruction_loss: 155.1610 - kl_loss: 6.5401 - lr: 0.0010\n",
            "Epoch 5/1000\n",
            "547/547 [==============================] - 10s 18ms/step - loss: 159.8787 - reconstruction_loss: 153.0970 - kl_loss: 6.6212 - lr: 0.0010\n",
            "Epoch 6/1000\n",
            "547/547 [==============================] - 10s 18ms/step - loss: 158.6397 - reconstruction_loss: 151.5973 - kl_loss: 6.6360 - lr: 0.0010\n",
            "Epoch 7/1000\n",
            "547/547 [==============================] - 10s 18ms/step - loss: 157.4898 - reconstruction_loss: 150.6313 - kl_loss: 6.6701 - lr: 0.0010\n",
            "Epoch 8/1000\n",
            "547/547 [==============================] - 10s 18ms/step - loss: 156.2632 - reconstruction_loss: 149.7409 - kl_loss: 6.6961 - lr: 0.0010\n",
            "Epoch 9/1000\n",
            "547/547 [==============================] - 10s 18ms/step - loss: 155.6809 - reconstruction_loss: 149.0259 - kl_loss: 6.6938 - lr: 0.0010\n",
            "Epoch 10/1000\n",
            "547/547 [==============================] - 10s 18ms/step - loss: 155.1057 - reconstruction_loss: 148.3968 - kl_loss: 6.7054 - lr: 0.0010\n",
            "Epoch 11/1000\n",
            "547/547 [==============================] - 10s 18ms/step - loss: 154.2425 - reconstruction_loss: 147.8818 - kl_loss: 6.7135 - lr: 0.0010\n",
            "Epoch 12/1000\n",
            "547/547 [==============================] - 10s 18ms/step - loss: 154.1472 - reconstruction_loss: 147.5445 - kl_loss: 6.7054 - lr: 0.0010\n",
            "Epoch 13/1000\n",
            "547/547 [==============================] - 10s 18ms/step - loss: 153.9716 - reconstruction_loss: 147.0902 - kl_loss: 6.7079 - lr: 0.0010\n",
            "Epoch 14/1000\n",
            "547/547 [==============================] - 10s 18ms/step - loss: 153.5331 - reconstruction_loss: 146.7995 - kl_loss: 6.6853 - lr: 0.0010\n",
            "Epoch 15/1000\n",
            "547/547 [==============================] - 10s 18ms/step - loss: 152.8860 - reconstruction_loss: 146.4649 - kl_loss: 6.6797 - lr: 0.0010\n",
            "Epoch 16/1000\n",
            "547/547 [==============================] - 10s 18ms/step - loss: 152.4326 - reconstruction_loss: 146.1360 - kl_loss: 6.6701 - lr: 0.0010\n",
            "Epoch 17/1000\n",
            "547/547 [==============================] - 10s 18ms/step - loss: 152.2898 - reconstruction_loss: 145.9186 - kl_loss: 6.6606 - lr: 0.0010\n",
            "Epoch 18/1000\n",
            "547/547 [==============================] - 10s 18ms/step - loss: 152.3634 - reconstruction_loss: 145.5731 - kl_loss: 6.6604 - lr: 0.0010\n",
            "Epoch 19/1000\n",
            "547/547 [==============================] - 10s 18ms/step - loss: 152.2531 - reconstruction_loss: 145.3867 - kl_loss: 6.6437 - lr: 0.0010\n",
            "Epoch 20/1000\n",
            "547/547 [==============================] - 10s 18ms/step - loss: 151.8251 - reconstruction_loss: 145.1286 - kl_loss: 6.6535 - lr: 0.0010\n",
            "Epoch 21/1000\n",
            "547/547 [==============================] - 10s 18ms/step - loss: 151.1844 - reconstruction_loss: 144.9486 - kl_loss: 6.6432 - lr: 0.0010\n",
            "Epoch 22/1000\n",
            "547/547 [==============================] - 10s 18ms/step - loss: 151.1741 - reconstruction_loss: 144.7355 - kl_loss: 6.6465 - lr: 0.0010\n",
            "Epoch 23/1000\n",
            "547/547 [==============================] - 10s 18ms/step - loss: 150.9454 - reconstruction_loss: 144.5155 - kl_loss: 6.6408 - lr: 0.0010\n",
            "Epoch 24/1000\n",
            "547/547 [==============================] - 10s 18ms/step - loss: 150.7187 - reconstruction_loss: 144.4206 - kl_loss: 6.6410 - lr: 0.0010\n",
            "Epoch 25/1000\n",
            "547/547 [==============================] - 10s 18ms/step - loss: 150.9578 - reconstruction_loss: 144.1594 - kl_loss: 6.6406 - lr: 0.0010\n",
            "Epoch 26/1000\n",
            "547/547 [==============================] - 10s 18ms/step - loss: 150.4427 - reconstruction_loss: 144.1337 - kl_loss: 6.6319 - lr: 0.0010\n",
            "Epoch 27/1000\n",
            "547/547 [==============================] - 10s 18ms/step - loss: 150.7556 - reconstruction_loss: 143.9388 - kl_loss: 6.6320 - lr: 0.0010\n",
            "Epoch 28/1000\n",
            "547/547 [==============================] - 10s 18ms/step - loss: 150.3386 - reconstruction_loss: 143.7641 - kl_loss: 6.6366 - lr: 0.0010\n",
            "Epoch 29/1000\n",
            "547/547 [==============================] - 10s 18ms/step - loss: 149.8949 - reconstruction_loss: 143.6466 - kl_loss: 6.6286 - lr: 0.0010\n",
            "Epoch 30/1000\n",
            "547/547 [==============================] - 10s 18ms/step - loss: 149.9902 - reconstruction_loss: 143.5166 - kl_loss: 6.6514 - lr: 0.0010\n",
            "Epoch 31/1000\n",
            "547/547 [==============================] - 10s 18ms/step - loss: 150.1654 - reconstruction_loss: 143.4068 - kl_loss: 6.6397 - lr: 0.0010\n",
            "Epoch 32/1000\n",
            "547/547 [==============================] - 10s 18ms/step - loss: 149.5018 - reconstruction_loss: 143.3180 - kl_loss: 6.6338 - lr: 0.0010\n",
            "Epoch 33/1000\n",
            "547/547 [==============================] - 10s 18ms/step - loss: 149.8092 - reconstruction_loss: 143.1898 - kl_loss: 6.6462 - lr: 0.0010\n",
            "Epoch 34/1000\n",
            "547/547 [==============================] - 10s 18ms/step - loss: 149.4587 - reconstruction_loss: 143.0671 - kl_loss: 6.6461 - lr: 0.0010\n",
            "Epoch 35/1000\n",
            "547/547 [==============================] - 10s 18ms/step - loss: 149.5727 - reconstruction_loss: 142.9708 - kl_loss: 6.6391 - lr: 0.0010\n",
            "Epoch 36/1000\n",
            "547/547 [==============================] - 10s 18ms/step - loss: 149.0215 - reconstruction_loss: 142.8130 - kl_loss: 6.6525 - lr: 0.0010\n",
            "Epoch 37/1000\n",
            "547/547 [==============================] - 10s 18ms/step - loss: 149.4223 - reconstruction_loss: 142.8101 - kl_loss: 6.6612 - lr: 0.0010\n",
            "Epoch 38/1000\n",
            "547/547 [==============================] - 10s 18ms/step - loss: 149.0316 - reconstruction_loss: 142.6289 - kl_loss: 6.6638 - lr: 0.0010\n",
            "Epoch 39/1000\n",
            "547/547 [==============================] - 10s 18ms/step - loss: 148.9838 - reconstruction_loss: 142.4333 - kl_loss: 6.6651 - lr: 0.0010\n",
            "Epoch 40/1000\n",
            "547/547 [==============================] - 10s 18ms/step - loss: 149.0611 - reconstruction_loss: 142.4415 - kl_loss: 6.6668 - lr: 0.0010\n",
            "Epoch 41/1000\n",
            "547/547 [==============================] - 10s 18ms/step - loss: 149.0391 - reconstruction_loss: 142.3313 - kl_loss: 6.6753 - lr: 0.0010\n",
            "Epoch 42/1000\n",
            "547/547 [==============================] - 10s 18ms/step - loss: 149.2988 - reconstruction_loss: 142.3236 - kl_loss: 6.6743 - lr: 0.0010\n",
            "Epoch 43/1000\n",
            "547/547 [==============================] - 10s 18ms/step - loss: 148.7035 - reconstruction_loss: 142.1692 - kl_loss: 6.6797 - lr: 0.0010\n",
            "Epoch 44/1000\n",
            "547/547 [==============================] - 10s 18ms/step - loss: 148.4162 - reconstruction_loss: 142.0195 - kl_loss: 6.6848 - lr: 0.0010\n",
            "Epoch 45/1000\n",
            "547/547 [==============================] - 10s 18ms/step - loss: 148.9664 - reconstruction_loss: 142.0535 - kl_loss: 6.6720 - lr: 0.0010\n",
            "Epoch 46/1000\n",
            "547/547 [==============================] - 10s 18ms/step - loss: 148.6082 - reconstruction_loss: 142.0115 - kl_loss: 6.6818 - lr: 0.0010\n",
            "Epoch 47/1000\n",
            "547/547 [==============================] - 10s 18ms/step - loss: 148.6066 - reconstruction_loss: 141.8607 - kl_loss: 6.6920 - lr: 0.0010\n",
            "Epoch 48/1000\n",
            "547/547 [==============================] - 10s 18ms/step - loss: 148.5762 - reconstruction_loss: 141.8456 - kl_loss: 6.6962 - lr: 0.0010\n",
            "Epoch 49/1000\n",
            "547/547 [==============================] - 10s 18ms/step - loss: 148.3098 - reconstruction_loss: 141.7458 - kl_loss: 6.7040 - lr: 0.0010\n",
            "Epoch 50/1000\n",
            "547/547 [==============================] - 10s 18ms/step - loss: 148.3898 - reconstruction_loss: 141.7106 - kl_loss: 6.7125 - lr: 0.0010\n",
            "Epoch 51/1000\n",
            "547/547 [==============================] - 10s 18ms/step - loss: 148.4461 - reconstruction_loss: 141.6530 - kl_loss: 6.7094 - lr: 0.0010\n",
            "Epoch 52/1000\n",
            "547/547 [==============================] - 10s 18ms/step - loss: 148.2678 - reconstruction_loss: 141.6435 - kl_loss: 6.6991 - lr: 0.0010\n",
            "Epoch 53/1000\n",
            "547/547 [==============================] - 10s 18ms/step - loss: 147.7492 - reconstruction_loss: 141.5381 - kl_loss: 6.7107 - lr: 0.0010\n",
            "Epoch 54/1000\n",
            "547/547 [==============================] - 10s 18ms/step - loss: 148.0949 - reconstruction_loss: 141.4303 - kl_loss: 6.7155 - lr: 0.0010\n",
            "Epoch 55/1000\n",
            "547/547 [==============================] - 10s 18ms/step - loss: 148.0151 - reconstruction_loss: 141.4266 - kl_loss: 6.7118 - lr: 0.0010\n",
            "Epoch 56/1000\n",
            "547/547 [==============================] - 10s 18ms/step - loss: 147.9668 - reconstruction_loss: 141.3898 - kl_loss: 6.7282 - lr: 0.0010\n",
            "Epoch 57/1000\n",
            "547/547 [==============================] - 10s 18ms/step - loss: 147.7390 - reconstruction_loss: 141.2385 - kl_loss: 6.7337 - lr: 0.0010\n",
            "Epoch 58/1000\n",
            "547/547 [==============================] - 10s 18ms/step - loss: 147.8741 - reconstruction_loss: 141.1919 - kl_loss: 6.7300 - lr: 0.0010\n",
            "Epoch 59/1000\n",
            "547/547 [==============================] - 10s 18ms/step - loss: 147.7945 - reconstruction_loss: 141.1385 - kl_loss: 6.7337 - lr: 0.0010\n",
            "Epoch 60/1000\n",
            "547/547 [==============================] - 10s 18ms/step - loss: 147.7449 - reconstruction_loss: 141.1843 - kl_loss: 6.7161 - lr: 0.0010\n",
            "Epoch 61/1000\n",
            "547/547 [==============================] - 10s 18ms/step - loss: 147.4850 - reconstruction_loss: 141.0462 - kl_loss: 6.7330 - lr: 0.0010\n",
            "Epoch 62/1000\n",
            "547/547 [==============================] - 10s 18ms/step - loss: 147.6238 - reconstruction_loss: 140.9334 - kl_loss: 6.7275 - lr: 0.0010\n",
            "Epoch 63/1000\n",
            "547/547 [==============================] - 10s 18ms/step - loss: 147.6157 - reconstruction_loss: 140.9775 - kl_loss: 6.7333 - lr: 0.0010\n",
            "Epoch 64/1000\n",
            "547/547 [==============================] - 10s 18ms/step - loss: 147.4326 - reconstruction_loss: 140.8673 - kl_loss: 6.7549 - lr: 0.0010\n",
            "Epoch 65/1000\n",
            "547/547 [==============================] - 10s 18ms/step - loss: 147.5479 - reconstruction_loss: 140.8869 - kl_loss: 6.7497 - lr: 0.0010\n",
            "Epoch 66/1000\n",
            "547/547 [==============================] - 10s 18ms/step - loss: 147.3650 - reconstruction_loss: 140.8333 - kl_loss: 6.7556 - lr: 0.0010\n",
            "Epoch 67/1000\n",
            "547/547 [==============================] - 10s 18ms/step - loss: 147.4850 - reconstruction_loss: 140.7340 - kl_loss: 6.7505 - lr: 0.0010\n",
            "Epoch 68/1000\n",
            "547/547 [==============================] - 10s 18ms/step - loss: 147.3538 - reconstruction_loss: 140.6510 - kl_loss: 6.7434 - lr: 0.0010\n",
            "Epoch 69/1000\n",
            "547/547 [==============================] - 10s 18ms/step - loss: 147.3512 - reconstruction_loss: 140.6010 - kl_loss: 6.7592 - lr: 0.0010\n",
            "Epoch 70/1000\n",
            "547/547 [==============================] - 10s 18ms/step - loss: 147.3898 - reconstruction_loss: 140.6635 - kl_loss: 6.7536 - lr: 0.0010\n",
            "Epoch 71/1000\n",
            "547/547 [==============================] - 10s 18ms/step - loss: 147.1953 - reconstruction_loss: 140.5680 - kl_loss: 6.7747 - lr: 0.0010\n",
            "Epoch 72/1000\n",
            "547/547 [==============================] - 10s 18ms/step - loss: 147.1042 - reconstruction_loss: 140.5381 - kl_loss: 6.7637 - lr: 0.0010\n",
            "Epoch 73/1000\n",
            "547/547 [==============================] - 10s 18ms/step - loss: 147.2153 - reconstruction_loss: 140.5018 - kl_loss: 6.7508 - lr: 0.0010\n",
            "Epoch 74/1000\n",
            "547/547 [==============================] - 10s 18ms/step - loss: 147.2949 - reconstruction_loss: 140.4542 - kl_loss: 6.7487 - lr: 0.0010\n",
            "Epoch 75/1000\n",
            "547/547 [==============================] - 10s 18ms/step - loss: 147.4199 - reconstruction_loss: 140.4261 - kl_loss: 6.7712 - lr: 0.0010\n",
            "Epoch 76/1000\n",
            "547/547 [==============================] - 10s 18ms/step - loss: 146.9938 - reconstruction_loss: 140.3943 - kl_loss: 6.7574 - lr: 0.0010\n",
            "Epoch 77/1000\n",
            "547/547 [==============================] - 10s 18ms/step - loss: 147.0669 - reconstruction_loss: 140.3221 - kl_loss: 6.7775 - lr: 0.0010\n",
            "Epoch 78/1000\n",
            "547/547 [==============================] - 10s 18ms/step - loss: 146.5414 - reconstruction_loss: 140.3455 - kl_loss: 6.7714 - lr: 0.0010\n",
            "Epoch 79/1000\n",
            "547/547 [==============================] - 10s 18ms/step - loss: 146.5626 - reconstruction_loss: 140.1952 - kl_loss: 6.7579 - lr: 0.0010\n",
            "Epoch 80/1000\n",
            "547/547 [==============================] - 10s 18ms/step - loss: 147.0496 - reconstruction_loss: 140.2079 - kl_loss: 6.7669 - lr: 0.0010\n",
            "Epoch 81/1000\n",
            "547/547 [==============================] - 10s 18ms/step - loss: 146.4331 - reconstruction_loss: 140.1292 - kl_loss: 6.7640 - lr: 0.0010\n",
            "Epoch 82/1000\n",
            "547/547 [==============================] - 10s 18ms/step - loss: 146.9303 - reconstruction_loss: 140.1663 - kl_loss: 6.7823 - lr: 0.0010\n",
            "Epoch 83/1000\n",
            "547/547 [==============================] - 10s 18ms/step - loss: 146.7821 - reconstruction_loss: 140.1669 - kl_loss: 6.7960 - lr: 0.0010\n",
            "Epoch 84/1000\n",
            "547/547 [==============================] - 10s 18ms/step - loss: 146.6491 - reconstruction_loss: 140.0528 - kl_loss: 6.7764 - lr: 0.0010\n",
            "Epoch 85/1000\n",
            "547/547 [==============================] - 10s 18ms/step - loss: 146.3891 - reconstruction_loss: 140.1069 - kl_loss: 6.8016 - lr: 0.0010\n",
            "Epoch 86/1000\n",
            "547/547 [==============================] - 10s 18ms/step - loss: 146.4839 - reconstruction_loss: 139.9853 - kl_loss: 6.7907 - lr: 0.0010\n",
            "Epoch 87/1000\n",
            "547/547 [==============================] - 10s 18ms/step - loss: 146.7692 - reconstruction_loss: 140.0384 - kl_loss: 6.7861 - lr: 0.0010\n",
            "Epoch 88/1000\n",
            "547/547 [==============================] - 10s 18ms/step - loss: 146.2779 - reconstruction_loss: 139.9085 - kl_loss: 6.7959 - lr: 0.0010\n",
            "Epoch 89/1000\n",
            "547/547 [==============================] - 10s 18ms/step - loss: 146.6373 - reconstruction_loss: 139.8748 - kl_loss: 6.7870 - lr: 0.0010\n",
            "Epoch 90/1000\n",
            "547/547 [==============================] - 10s 18ms/step - loss: 146.4010 - reconstruction_loss: 139.9048 - kl_loss: 6.7799 - lr: 0.0010\n",
            "Epoch 91/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 146.3816 - reconstruction_loss: 139.8232 - kl_loss: 6.7862 - lr: 0.0010\n",
            "Epoch 92/1000\n",
            "547/547 [==============================] - 10s 18ms/step - loss: 146.5137 - reconstruction_loss: 139.8642 - kl_loss: 6.8013 - lr: 0.0010\n",
            "Epoch 93/1000\n",
            "547/547 [==============================] - 10s 18ms/step - loss: 146.5863 - reconstruction_loss: 139.7517 - kl_loss: 6.7847 - lr: 0.0010\n",
            "Epoch 94/1000\n",
            "547/547 [==============================] - 10s 18ms/step - loss: 146.4421 - reconstruction_loss: 139.7144 - kl_loss: 6.8072 - lr: 0.0010\n",
            "Epoch 95/1000\n",
            "547/547 [==============================] - 10s 18ms/step - loss: 146.5223 - reconstruction_loss: 139.7262 - kl_loss: 6.8065 - lr: 0.0010\n",
            "Epoch 96/1000\n",
            "547/547 [==============================] - 10s 18ms/step - loss: 146.4561 - reconstruction_loss: 139.8224 - kl_loss: 6.7928 - lr: 0.0010\n",
            "Epoch 97/1000\n",
            "547/547 [==============================] - 10s 18ms/step - loss: 146.3032 - reconstruction_loss: 139.7467 - kl_loss: 6.8222 - lr: 0.0010\n",
            "Epoch 98/1000\n",
            "547/547 [==============================] - 10s 18ms/step - loss: 145.7113 - reconstruction_loss: 138.6910 - kl_loss: 6.8214 - lr: 5.0000e-04\n",
            "Epoch 99/1000\n",
            "547/547 [==============================] - 10s 18ms/step - loss: 145.3613 - reconstruction_loss: 138.5700 - kl_loss: 6.8559 - lr: 5.0000e-04\n",
            "Epoch 100/1000\n",
            "547/547 [==============================] - 10s 18ms/step - loss: 145.3532 - reconstruction_loss: 138.4698 - kl_loss: 6.8581 - lr: 5.0000e-04\n",
            "Epoch 101/1000\n",
            "547/547 [==============================] - 10s 18ms/step - loss: 144.9085 - reconstruction_loss: 138.4799 - kl_loss: 6.8540 - lr: 5.0000e-04\n",
            "Epoch 102/1000\n",
            "547/547 [==============================] - 10s 18ms/step - loss: 145.2549 - reconstruction_loss: 138.4413 - kl_loss: 6.8512 - lr: 5.0000e-04\n",
            "Epoch 103/1000\n",
            "547/547 [==============================] - 10s 18ms/step - loss: 145.0861 - reconstruction_loss: 138.4183 - kl_loss: 6.8546 - lr: 5.0000e-04\n",
            "Epoch 104/1000\n",
            "547/547 [==============================] - 10s 18ms/step - loss: 145.2151 - reconstruction_loss: 138.3357 - kl_loss: 6.8710 - lr: 5.0000e-04\n",
            "Epoch 105/1000\n",
            "547/547 [==============================] - 10s 18ms/step - loss: 145.1501 - reconstruction_loss: 138.3352 - kl_loss: 6.8719 - lr: 5.0000e-04\n",
            "Epoch 106/1000\n",
            "547/547 [==============================] - 10s 18ms/step - loss: 145.0728 - reconstruction_loss: 138.3009 - kl_loss: 6.8812 - lr: 5.0000e-04\n",
            "Epoch 107/1000\n",
            "547/547 [==============================] - 10s 18ms/step - loss: 145.5586 - reconstruction_loss: 138.3333 - kl_loss: 6.8624 - lr: 5.0000e-04\n",
            "Epoch 108/1000\n",
            "547/547 [==============================] - 10s 18ms/step - loss: 145.0125 - reconstruction_loss: 138.2994 - kl_loss: 6.8935 - lr: 5.0000e-04\n",
            "Epoch 109/1000\n",
            "547/547 [==============================] - 10s 18ms/step - loss: 145.1377 - reconstruction_loss: 138.2636 - kl_loss: 6.8845 - lr: 5.0000e-04\n",
            "Epoch 110/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 144.6309 - reconstruction_loss: 138.2051 - kl_loss: 6.8822 - lr: 5.0000e-04\n",
            "Epoch 111/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 144.9289 - reconstruction_loss: 138.1964 - kl_loss: 6.8917 - lr: 5.0000e-04\n",
            "Epoch 112/1000\n",
            "547/547 [==============================] - 10s 18ms/step - loss: 144.7564 - reconstruction_loss: 138.1817 - kl_loss: 6.8952 - lr: 5.0000e-04\n",
            "Epoch 113/1000\n",
            "547/547 [==============================] - 10s 18ms/step - loss: 144.7649 - reconstruction_loss: 138.1826 - kl_loss: 6.8940 - lr: 5.0000e-04\n",
            "Epoch 114/1000\n",
            "547/547 [==============================] - 10s 18ms/step - loss: 144.9465 - reconstruction_loss: 138.1511 - kl_loss: 6.8995 - lr: 5.0000e-04\n",
            "Epoch 115/1000\n",
            "547/547 [==============================] - 10s 18ms/step - loss: 144.8192 - reconstruction_loss: 138.0947 - kl_loss: 6.9021 - lr: 5.0000e-04\n",
            "Epoch 116/1000\n",
            "547/547 [==============================] - 10s 18ms/step - loss: 144.9570 - reconstruction_loss: 138.1141 - kl_loss: 6.8856 - lr: 5.0000e-04\n",
            "Epoch 117/1000\n",
            "547/547 [==============================] - 10s 18ms/step - loss: 144.6675 - reconstruction_loss: 138.1045 - kl_loss: 6.9060 - lr: 5.0000e-04\n",
            "Epoch 118/1000\n",
            "547/547 [==============================] - 10s 18ms/step - loss: 144.6469 - reconstruction_loss: 138.0903 - kl_loss: 6.9161 - lr: 5.0000e-04\n",
            "Epoch 119/1000\n",
            "547/547 [==============================] - 10s 18ms/step - loss: 144.5197 - reconstruction_loss: 137.5273 - kl_loss: 6.9194 - lr: 2.5000e-04\n",
            "Epoch 120/1000\n",
            "547/547 [==============================] - 10s 18ms/step - loss: 144.4493 - reconstruction_loss: 137.4353 - kl_loss: 6.9295 - lr: 2.5000e-04\n",
            "Epoch 121/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 144.2763 - reconstruction_loss: 137.4329 - kl_loss: 6.9458 - lr: 2.5000e-04\n",
            "Epoch 122/1000\n",
            "547/547 [==============================] - 10s 18ms/step - loss: 144.4472 - reconstruction_loss: 137.3786 - kl_loss: 6.9358 - lr: 2.5000e-04\n",
            "Epoch 123/1000\n",
            "547/547 [==============================] - 10s 18ms/step - loss: 144.6972 - reconstruction_loss: 137.4083 - kl_loss: 6.9271 - lr: 2.5000e-04\n",
            "Epoch 124/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 144.0049 - reconstruction_loss: 137.3515 - kl_loss: 6.9516 - lr: 2.5000e-04\n",
            "Epoch 125/1000\n",
            "547/547 [==============================] - 10s 18ms/step - loss: 143.9894 - reconstruction_loss: 137.3489 - kl_loss: 6.9319 - lr: 2.5000e-04\n",
            "Epoch 126/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 144.1385 - reconstruction_loss: 137.3332 - kl_loss: 6.9377 - lr: 2.5000e-04\n",
            "Epoch 127/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 144.2795 - reconstruction_loss: 137.3320 - kl_loss: 6.9437 - lr: 2.5000e-04\n",
            "Epoch 128/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 144.1569 - reconstruction_loss: 137.2899 - kl_loss: 6.9423 - lr: 2.5000e-04\n",
            "Epoch 129/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 143.8282 - reconstruction_loss: 137.3039 - kl_loss: 6.9516 - lr: 2.5000e-04\n",
            "Epoch 130/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 143.9048 - reconstruction_loss: 137.2690 - kl_loss: 6.9522 - lr: 2.5000e-04\n",
            "Epoch 131/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 143.8028 - reconstruction_loss: 137.2643 - kl_loss: 6.9602 - lr: 2.5000e-04\n",
            "Epoch 132/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 144.1568 - reconstruction_loss: 137.2446 - kl_loss: 6.9458 - lr: 2.5000e-04\n",
            "Epoch 133/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 144.1287 - reconstruction_loss: 137.2447 - kl_loss: 6.9529 - lr: 2.5000e-04\n",
            "Epoch 134/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 144.1221 - reconstruction_loss: 137.2868 - kl_loss: 6.9656 - lr: 2.5000e-04\n",
            "Epoch 135/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 144.2944 - reconstruction_loss: 137.2215 - kl_loss: 6.9678 - lr: 2.5000e-04\n",
            "Epoch 136/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 144.1434 - reconstruction_loss: 137.2097 - kl_loss: 6.9762 - lr: 2.5000e-04\n",
            "Epoch 137/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 144.1485 - reconstruction_loss: 137.1976 - kl_loss: 6.9751 - lr: 2.5000e-04\n",
            "Epoch 138/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 144.3508 - reconstruction_loss: 137.2037 - kl_loss: 6.9706 - lr: 2.5000e-04\n",
            "Epoch 139/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 144.1010 - reconstruction_loss: 137.1907 - kl_loss: 6.9552 - lr: 2.5000e-04\n",
            "Epoch 140/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 144.0688 - reconstruction_loss: 137.1800 - kl_loss: 6.9863 - lr: 2.5000e-04\n",
            "Epoch 141/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 144.1549 - reconstruction_loss: 137.1400 - kl_loss: 6.9587 - lr: 2.5000e-04\n",
            "Epoch 142/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 143.7016 - reconstruction_loss: 137.1512 - kl_loss: 6.9608 - lr: 2.5000e-04\n",
            "Epoch 143/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 143.8482 - reconstruction_loss: 137.1425 - kl_loss: 6.9796 - lr: 2.5000e-04\n",
            "Epoch 144/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 144.1243 - reconstruction_loss: 137.1348 - kl_loss: 6.9745 - lr: 2.5000e-04\n",
            "Epoch 145/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 143.8152 - reconstruction_loss: 136.8263 - kl_loss: 6.9759 - lr: 1.2500e-04\n",
            "Epoch 146/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 143.6684 - reconstruction_loss: 136.8092 - kl_loss: 6.9911 - lr: 1.2500e-04\n",
            "Epoch 147/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 143.8429 - reconstruction_loss: 136.7541 - kl_loss: 6.9825 - lr: 1.2500e-04\n",
            "Epoch 148/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 143.6438 - reconstruction_loss: 136.7340 - kl_loss: 6.9781 - lr: 1.2500e-04\n",
            "Epoch 149/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 143.7940 - reconstruction_loss: 136.7759 - kl_loss: 6.9946 - lr: 1.2500e-04\n",
            "Epoch 150/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 143.6573 - reconstruction_loss: 136.7261 - kl_loss: 6.9911 - lr: 1.2500e-04\n",
            "Epoch 151/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 143.6315 - reconstruction_loss: 136.7566 - kl_loss: 6.9966 - lr: 1.2500e-04\n",
            "Epoch 152/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 143.7433 - reconstruction_loss: 136.5792 - kl_loss: 6.9987 - lr: 6.2500e-05\n",
            "Epoch 153/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 143.4923 - reconstruction_loss: 136.5672 - kl_loss: 7.0063 - lr: 6.2500e-05\n",
            "Epoch 154/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 143.6655 - reconstruction_loss: 136.5748 - kl_loss: 7.0137 - lr: 6.2500e-05\n",
            "Epoch 155/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 143.6293 - reconstruction_loss: 136.5400 - kl_loss: 7.0118 - lr: 6.2500e-05\n",
            "Epoch 156/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 143.3774 - reconstruction_loss: 136.5440 - kl_loss: 7.0130 - lr: 6.2500e-05\n",
            "Epoch 157/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 143.2798 - reconstruction_loss: 136.5307 - kl_loss: 7.0145 - lr: 6.2500e-05\n",
            "Epoch 158/1000\n",
            "547/547 [==============================] - 10s 18ms/step - loss: 143.7283 - reconstruction_loss: 136.5405 - kl_loss: 7.0150 - lr: 6.2500e-05\n",
            "Epoch 159/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 143.5204 - reconstruction_loss: 136.5271 - kl_loss: 7.0135 - lr: 6.2500e-05\n",
            "Epoch 160/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 143.1853 - reconstruction_loss: 136.5125 - kl_loss: 7.0050 - lr: 6.2500e-05\n",
            "Epoch 161/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 143.7959 - reconstruction_loss: 136.5282 - kl_loss: 7.0041 - lr: 6.2500e-05\n",
            "Epoch 162/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 143.4707 - reconstruction_loss: 136.5157 - kl_loss: 7.0164 - lr: 6.2500e-05\n",
            "Epoch 163/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 143.4090 - reconstruction_loss: 136.5280 - kl_loss: 7.0147 - lr: 6.2500e-05\n",
            "Epoch 164/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 143.3957 - reconstruction_loss: 136.4429 - kl_loss: 7.0241 - lr: 3.1250e-05\n",
            "Epoch 165/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 143.3728 - reconstruction_loss: 136.4231 - kl_loss: 7.0222 - lr: 3.1250e-05\n",
            "Epoch 166/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 142.9276 - reconstruction_loss: 136.4096 - kl_loss: 7.0229 - lr: 3.1250e-05\n",
            "Epoch 167/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 143.2349 - reconstruction_loss: 136.4358 - kl_loss: 7.0230 - lr: 3.1250e-05\n",
            "Epoch 168/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 143.1834 - reconstruction_loss: 136.4118 - kl_loss: 7.0265 - lr: 3.1250e-05\n",
            "Epoch 169/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 143.5967 - reconstruction_loss: 136.3923 - kl_loss: 7.0250 - lr: 3.1250e-05\n",
            "Epoch 170/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 143.2957 - reconstruction_loss: 136.4135 - kl_loss: 7.0272 - lr: 3.1250e-05\n",
            "Epoch 171/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 143.8962 - reconstruction_loss: 136.4010 - kl_loss: 7.0278 - lr: 3.1250e-05\n",
            "Epoch 172/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 143.7509 - reconstruction_loss: 136.3658 - kl_loss: 7.0205 - lr: 3.1250e-05\n",
            "Epoch 173/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 143.5168 - reconstruction_loss: 136.4332 - kl_loss: 7.0190 - lr: 3.1250e-05\n",
            "Epoch 174/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 143.4822 - reconstruction_loss: 136.3761 - kl_loss: 7.0217 - lr: 3.1250e-05\n",
            "Epoch 175/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 143.5168 - reconstruction_loss: 136.3847 - kl_loss: 7.0255 - lr: 3.1250e-05\n",
            "Epoch 176/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 143.0376 - reconstruction_loss: 136.3365 - kl_loss: 7.0247 - lr: 1.5625e-05\n",
            "Epoch 177/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 143.2208 - reconstruction_loss: 136.3664 - kl_loss: 7.0249 - lr: 1.5625e-05\n",
            "Epoch 178/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 143.3235 - reconstruction_loss: 136.3327 - kl_loss: 7.0287 - lr: 1.5625e-05\n",
            "Epoch 179/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 143.2302 - reconstruction_loss: 136.3425 - kl_loss: 7.0244 - lr: 1.5625e-05\n",
            "Epoch 180/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 143.2985 - reconstruction_loss: 136.3115 - kl_loss: 7.0276 - lr: 1.0000e-05\n",
            "Epoch 181/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 143.1494 - reconstruction_loss: 136.3337 - kl_loss: 7.0278 - lr: 1.0000e-05\n",
            "Epoch 182/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 143.5771 - reconstruction_loss: 136.3074 - kl_loss: 7.0309 - lr: 1.0000e-05\n",
            "Epoch 183/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 143.4281 - reconstruction_loss: 136.3325 - kl_loss: 7.0313 - lr: 1.0000e-05\n",
            "Epoch 184/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 143.2070 - reconstruction_loss: 136.3166 - kl_loss: 7.0320 - lr: 1.0000e-05\n",
            "Epoch 185/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 142.9819 - reconstruction_loss: 136.2920 - kl_loss: 7.0310 - lr: 1.0000e-05\n",
            "Epoch 186/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 143.3292 - reconstruction_loss: 136.3115 - kl_loss: 7.0300 - lr: 1.0000e-05\n",
            "Epoch 187/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 143.7138 - reconstruction_loss: 136.3133 - kl_loss: 7.0313 - lr: 1.0000e-05\n",
            "Epoch 188/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 143.3439 - reconstruction_loss: 136.3106 - kl_loss: 7.0307 - lr: 1.0000e-05\n",
            "Epoch 189/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 143.2944 - reconstruction_loss: 136.3222 - kl_loss: 7.0306 - lr: 1.0000e-05\n",
            "Epoch 190/1000\n",
            "547/547 [==============================] - 10s 19ms/step - loss: 143.2800 - reconstruction_loss: 136.3078 - kl_loss: 7.0324 - lr: 1.0000e-05\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f813049d8d0>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "\n",
        "#Train data\n",
        "x_train = np.expand_dims(x_train, -1).astype(\"float32\") / 255\n",
        "z_mean_train, _, _ = vae.encoder.predict(x_train)\n",
        "\n",
        "#Test data\n",
        "x_test = np.expand_dims(x_test, -1).astype(\"float32\") / 255\n",
        "z_mean_test, _, _ = vae.encoder.predict(x_test)\n",
        "\n",
        "z_mean_train.shape\n",
        "\n"
      ],
      "metadata": {
        "id": "c0UhR8QlJ-UK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a636317-36e8-4212-e5f3-8c9dbd6ff39e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model=keras.models.Sequential()\n",
        "model.add(keras.Input(shape=z_mean_train.shape[1:]))\n",
        "model.add(keras.layers.Dense(30,activation='relu'))\n",
        "model.add(keras.layers.Dense(10,activation='softmax'))"
      ],
      "metadata": {
        "id": "rZ2d5knMK93J"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks=[tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', #val_loss\n",
        "                                                factor=0.5,\n",
        "                                                patience=3,\n",
        "                                                min_lr=1e-5),\n",
        "           tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
        "                                            patience=5),\n",
        "           tf.keras.callbacks.ModelCheckpoint(filepath='my_model.h5',\n",
        "                                              monitor='val_loss',\n",
        "                                              save_best_only=True)]"
      ],
      "metadata": {
        "id": "hx8Miq7CdqQP"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=keras.losses.SparseCategoricalCrossentropy(),\n",
        "              optimizer=keras.optimizers.Adam(lr=0.001),\n",
        "              metrics=[keras.metrics.SparseCategoricalAccuracy()]) # "
      ],
      "metadata": {
        "id": "GgSDLEghN5B_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60c6904b-ca2c-4574-8daa-6c87b5b23f0e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history=model.fit(x=z_mean_train,y=y_train,\n",
        "          epochs=100,\n",
        "          batch_size=32,\n",
        "          validation_data=(z_mean_test,y_test),\n",
        "          callbacks=callbacks) #"
      ],
      "metadata": {
        "id": "0KB0PqkKOLF8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d05d0c5-fb93-49c9-e887-cfa88886d767"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 1.2658 - sparse_categorical_accuracy: 0.5664 - val_loss: 0.9408 - val_sparse_categorical_accuracy: 0.6789 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.9108 - sparse_categorical_accuracy: 0.7057 - val_loss: 0.8478 - val_sparse_categorical_accuracy: 0.7340 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.8518 - sparse_categorical_accuracy: 0.7263 - val_loss: 0.8099 - val_sparse_categorical_accuracy: 0.7529 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.8200 - sparse_categorical_accuracy: 0.7377 - val_loss: 0.7853 - val_sparse_categorical_accuracy: 0.7482 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.7978 - sparse_categorical_accuracy: 0.7419 - val_loss: 0.7653 - val_sparse_categorical_accuracy: 0.7526 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 0.7812 - sparse_categorical_accuracy: 0.7458 - val_loss: 0.7546 - val_sparse_categorical_accuracy: 0.7460 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.7695 - sparse_categorical_accuracy: 0.7477 - val_loss: 0.7438 - val_sparse_categorical_accuracy: 0.7593 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.7605 - sparse_categorical_accuracy: 0.7505 - val_loss: 0.7362 - val_sparse_categorical_accuracy: 0.7626 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.7534 - sparse_categorical_accuracy: 0.7508 - val_loss: 0.7294 - val_sparse_categorical_accuracy: 0.7620 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.7474 - sparse_categorical_accuracy: 0.7534 - val_loss: 0.7250 - val_sparse_categorical_accuracy: 0.7639 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.7421 - sparse_categorical_accuracy: 0.7551 - val_loss: 0.7192 - val_sparse_categorical_accuracy: 0.7662 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.7371 - sparse_categorical_accuracy: 0.7554 - val_loss: 0.7164 - val_sparse_categorical_accuracy: 0.7637 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.7331 - sparse_categorical_accuracy: 0.7573 - val_loss: 0.7103 - val_sparse_categorical_accuracy: 0.7691 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.7297 - sparse_categorical_accuracy: 0.7575 - val_loss: 0.7114 - val_sparse_categorical_accuracy: 0.7654 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.7264 - sparse_categorical_accuracy: 0.7582 - val_loss: 0.7059 - val_sparse_categorical_accuracy: 0.7670 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.7237 - sparse_categorical_accuracy: 0.7586 - val_loss: 0.7067 - val_sparse_categorical_accuracy: 0.7710 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.7213 - sparse_categorical_accuracy: 0.7600 - val_loss: 0.7032 - val_sparse_categorical_accuracy: 0.7701 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.7186 - sparse_categorical_accuracy: 0.7593 - val_loss: 0.7017 - val_sparse_categorical_accuracy: 0.7743 - lr: 0.0010\n",
            "Epoch 19/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.7168 - sparse_categorical_accuracy: 0.7601 - val_loss: 0.6969 - val_sparse_categorical_accuracy: 0.7744 - lr: 0.0010\n",
            "Epoch 20/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.7146 - sparse_categorical_accuracy: 0.7613 - val_loss: 0.7003 - val_sparse_categorical_accuracy: 0.7641 - lr: 0.0010\n",
            "Epoch 21/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.7129 - sparse_categorical_accuracy: 0.7613 - val_loss: 0.6956 - val_sparse_categorical_accuracy: 0.7681 - lr: 0.0010\n",
            "Epoch 22/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.7108 - sparse_categorical_accuracy: 0.7620 - val_loss: 0.6953 - val_sparse_categorical_accuracy: 0.7689 - lr: 0.0010\n",
            "Epoch 23/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.7091 - sparse_categorical_accuracy: 0.7617 - val_loss: 0.6906 - val_sparse_categorical_accuracy: 0.7742 - lr: 0.0010\n",
            "Epoch 24/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.7074 - sparse_categorical_accuracy: 0.7622 - val_loss: 0.6936 - val_sparse_categorical_accuracy: 0.7721 - lr: 0.0010\n",
            "Epoch 25/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.7058 - sparse_categorical_accuracy: 0.7631 - val_loss: 0.6909 - val_sparse_categorical_accuracy: 0.7702 - lr: 0.0010\n",
            "Epoch 26/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.7046 - sparse_categorical_accuracy: 0.7637 - val_loss: 0.6880 - val_sparse_categorical_accuracy: 0.7715 - lr: 0.0010\n",
            "Epoch 27/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.7033 - sparse_categorical_accuracy: 0.7642 - val_loss: 0.6890 - val_sparse_categorical_accuracy: 0.7759 - lr: 0.0010\n",
            "Epoch 28/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.7024 - sparse_categorical_accuracy: 0.7634 - val_loss: 0.6874 - val_sparse_categorical_accuracy: 0.7689 - lr: 0.0010\n",
            "Epoch 29/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.7008 - sparse_categorical_accuracy: 0.7642 - val_loss: 0.6844 - val_sparse_categorical_accuracy: 0.7767 - lr: 0.0010\n",
            "Epoch 30/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.6998 - sparse_categorical_accuracy: 0.7646 - val_loss: 0.6829 - val_sparse_categorical_accuracy: 0.7754 - lr: 0.0010\n",
            "Epoch 31/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.6987 - sparse_categorical_accuracy: 0.7650 - val_loss: 0.6865 - val_sparse_categorical_accuracy: 0.7649 - lr: 0.0010\n",
            "Epoch 32/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.6976 - sparse_categorical_accuracy: 0.7650 - val_loss: 0.6806 - val_sparse_categorical_accuracy: 0.7783 - lr: 0.0010\n",
            "Epoch 33/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.6968 - sparse_categorical_accuracy: 0.7659 - val_loss: 0.6785 - val_sparse_categorical_accuracy: 0.7746 - lr: 0.0010\n",
            "Epoch 34/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.6957 - sparse_categorical_accuracy: 0.7650 - val_loss: 0.6831 - val_sparse_categorical_accuracy: 0.7686 - lr: 0.0010\n",
            "Epoch 35/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.6951 - sparse_categorical_accuracy: 0.7655 - val_loss: 0.6805 - val_sparse_categorical_accuracy: 0.7723 - lr: 0.0010\n",
            "Epoch 36/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.6944 - sparse_categorical_accuracy: 0.7660 - val_loss: 0.6774 - val_sparse_categorical_accuracy: 0.7739 - lr: 0.0010\n",
            "Epoch 37/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.6938 - sparse_categorical_accuracy: 0.7662 - val_loss: 0.6757 - val_sparse_categorical_accuracy: 0.7747 - lr: 0.0010\n",
            "Epoch 38/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.6927 - sparse_categorical_accuracy: 0.7665 - val_loss: 0.6758 - val_sparse_categorical_accuracy: 0.7769 - lr: 0.0010\n",
            "Epoch 39/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.6925 - sparse_categorical_accuracy: 0.7665 - val_loss: 0.6749 - val_sparse_categorical_accuracy: 0.7778 - lr: 0.0010\n",
            "Epoch 40/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.6916 - sparse_categorical_accuracy: 0.7664 - val_loss: 0.6736 - val_sparse_categorical_accuracy: 0.7750 - lr: 0.0010\n",
            "Epoch 41/100\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 0.6909 - sparse_categorical_accuracy: 0.7660 - val_loss: 0.6734 - val_sparse_categorical_accuracy: 0.7771 - lr: 0.0010\n",
            "Epoch 42/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.6902 - sparse_categorical_accuracy: 0.7660 - val_loss: 0.6763 - val_sparse_categorical_accuracy: 0.7707 - lr: 0.0010\n",
            "Epoch 43/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.6898 - sparse_categorical_accuracy: 0.7665 - val_loss: 0.6732 - val_sparse_categorical_accuracy: 0.7753 - lr: 0.0010\n",
            "Epoch 44/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.6891 - sparse_categorical_accuracy: 0.7663 - val_loss: 0.6718 - val_sparse_categorical_accuracy: 0.7760 - lr: 0.0010\n",
            "Epoch 45/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.6890 - sparse_categorical_accuracy: 0.7662 - val_loss: 0.6702 - val_sparse_categorical_accuracy: 0.7734 - lr: 0.0010\n",
            "Epoch 46/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.6883 - sparse_categorical_accuracy: 0.7659 - val_loss: 0.6721 - val_sparse_categorical_accuracy: 0.7748 - lr: 0.0010\n",
            "Epoch 47/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.6876 - sparse_categorical_accuracy: 0.7675 - val_loss: 0.6701 - val_sparse_categorical_accuracy: 0.7766 - lr: 0.0010\n",
            "Epoch 48/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.6874 - sparse_categorical_accuracy: 0.7664 - val_loss: 0.6699 - val_sparse_categorical_accuracy: 0.7758 - lr: 0.0010\n",
            "Epoch 49/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.6866 - sparse_categorical_accuracy: 0.7665 - val_loss: 0.6676 - val_sparse_categorical_accuracy: 0.7760 - lr: 0.0010\n",
            "Epoch 50/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.6861 - sparse_categorical_accuracy: 0.7661 - val_loss: 0.6713 - val_sparse_categorical_accuracy: 0.7759 - lr: 0.0010\n",
            "Epoch 51/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.6855 - sparse_categorical_accuracy: 0.7661 - val_loss: 0.6722 - val_sparse_categorical_accuracy: 0.7720 - lr: 0.0010\n",
            "Epoch 52/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.6859 - sparse_categorical_accuracy: 0.7661 - val_loss: 0.6704 - val_sparse_categorical_accuracy: 0.7716 - lr: 0.0010\n",
            "Epoch 53/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.6835 - sparse_categorical_accuracy: 0.7666 - val_loss: 0.6666 - val_sparse_categorical_accuracy: 0.7731 - lr: 5.0000e-04\n",
            "Epoch 54/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.6833 - sparse_categorical_accuracy: 0.7682 - val_loss: 0.6658 - val_sparse_categorical_accuracy: 0.7763 - lr: 5.0000e-04\n",
            "Epoch 55/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.6832 - sparse_categorical_accuracy: 0.7672 - val_loss: 0.6675 - val_sparse_categorical_accuracy: 0.7719 - lr: 5.0000e-04\n",
            "Epoch 56/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.6828 - sparse_categorical_accuracy: 0.7676 - val_loss: 0.6664 - val_sparse_categorical_accuracy: 0.7754 - lr: 5.0000e-04\n",
            "Epoch 57/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.6825 - sparse_categorical_accuracy: 0.7675 - val_loss: 0.6659 - val_sparse_categorical_accuracy: 0.7764 - lr: 5.0000e-04\n",
            "Epoch 58/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.6813 - sparse_categorical_accuracy: 0.7673 - val_loss: 0.6652 - val_sparse_categorical_accuracy: 0.7757 - lr: 2.5000e-04\n",
            "Epoch 59/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.6813 - sparse_categorical_accuracy: 0.7678 - val_loss: 0.6647 - val_sparse_categorical_accuracy: 0.7764 - lr: 2.5000e-04\n",
            "Epoch 60/100\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 0.6812 - sparse_categorical_accuracy: 0.7678 - val_loss: 0.6645 - val_sparse_categorical_accuracy: 0.7773 - lr: 2.5000e-04\n",
            "Epoch 61/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.6811 - sparse_categorical_accuracy: 0.7677 - val_loss: 0.6650 - val_sparse_categorical_accuracy: 0.7757 - lr: 2.5000e-04\n",
            "Epoch 62/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.6811 - sparse_categorical_accuracy: 0.7672 - val_loss: 0.6644 - val_sparse_categorical_accuracy: 0.7764 - lr: 2.5000e-04\n",
            "Epoch 63/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.6808 - sparse_categorical_accuracy: 0.7678 - val_loss: 0.6638 - val_sparse_categorical_accuracy: 0.7751 - lr: 2.5000e-04\n",
            "Epoch 64/100\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 0.6808 - sparse_categorical_accuracy: 0.7680 - val_loss: 0.6642 - val_sparse_categorical_accuracy: 0.7763 - lr: 2.5000e-04\n",
            "Epoch 65/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.6806 - sparse_categorical_accuracy: 0.7681 - val_loss: 0.6635 - val_sparse_categorical_accuracy: 0.7758 - lr: 2.5000e-04\n",
            "Epoch 66/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.6806 - sparse_categorical_accuracy: 0.7677 - val_loss: 0.6651 - val_sparse_categorical_accuracy: 0.7770 - lr: 2.5000e-04\n",
            "Epoch 67/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.6805 - sparse_categorical_accuracy: 0.7674 - val_loss: 0.6649 - val_sparse_categorical_accuracy: 0.7763 - lr: 2.5000e-04\n",
            "Epoch 68/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.6804 - sparse_categorical_accuracy: 0.7676 - val_loss: 0.6646 - val_sparse_categorical_accuracy: 0.7770 - lr: 2.5000e-04\n",
            "Epoch 69/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.6798 - sparse_categorical_accuracy: 0.7676 - val_loss: 0.6637 - val_sparse_categorical_accuracy: 0.7767 - lr: 1.2500e-04\n",
            "Epoch 70/100\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.6798 - sparse_categorical_accuracy: 0.7681 - val_loss: 0.6635 - val_sparse_categorical_accuracy: 0.7774 - lr: 1.2500e-04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(history.history.keys())\n",
        "\n",
        "acc=history.history['sparse_categorical_accuracy']\n",
        "val_acc=history.history['sparse_categorical_accuracy']\n",
        "loss=history.history['loss']\n",
        "val_loss=history.history['val_loss']\n",
        "\n",
        "epochs=range(1,len(acc)+1)"
      ],
      "metadata": {
        "id": "sNwG_yN_SOx_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13032db6-7712-43c2-c776-d9906cfa6929"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['loss', 'sparse_categorical_accuracy', 'val_loss', 'val_sparse_categorical_accuracy', 'lr'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(epochs,loss,'bo',label='Train loss')\n",
        "plt.plot(epochs,val_loss,'g',label='Validation loss')\n",
        "plt.title('Losses')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend();\n"
      ],
      "metadata": {
        "id": "w0EiAkCAeMsF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "b0d84b78-cbf0-46a4-99e2-0215d85a65e3"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(epochs,acc,'bo',label='Train metric')\n",
        "plt.plot(epochs,val_acc,'g',label='Validation metric')\n",
        "plt.title('Metrics')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Metrics')\n",
        "plt.legend();"
      ],
      "metadata": {
        "id": "PmTxSV1xeU54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "aa5491e5-0836-4a3a-b8b2-df60d2fccfdb"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}