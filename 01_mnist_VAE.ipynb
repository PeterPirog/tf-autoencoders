{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "01-mnist-VAE.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOLh2b95Vdr542MiHwMkD+z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PeterPirog/tf-autoencoders/blob/main/01_mnist_VAE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Iey6lJGHKU2M"
      },
      "outputs": [],
      "source": [
        "#VAE CODER\n",
        "import tensorflow.keras as keras\n",
        "\n",
        "from keras import layers\n",
        "from keras import backend as K \n",
        "from keras.models import Model\n",
        "import numpy as np\n",
        "\n",
        "img_shape=(28,28,1)\n",
        "batch_size=16\n",
        "latent_dim =2\n",
        "\n",
        "input_img=keras.Input(shape=img_shape)\n",
        "\n",
        "x=layers.Conv2D(32,3,padding='same',activation='relu')(input_img)\n",
        "x=layers.Conv2D(64,3,padding='same',activation='relu',strides=(2,2))(x)\n",
        "x=layers.Conv2D(64,3,padding='same',activation='relu')(x)\n",
        "x=layers.Conv2D(64,3,padding='same',activation='relu')(x)\n",
        "\n",
        "shape_before_flattening=K.int_shape(x)\n",
        "\n",
        "x=layers.Flatten()(x)\n",
        "x=layers.Dense(32,activation='relu')(x)\n",
        "\n",
        "z_mean=layers.Dense(latent_dim)(x)\n",
        "z_log_var=layers.Dense(latent_dim)(x)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Sampling layer\n",
        "def sampling(args):\n",
        "  z_mean, z_log_var=args\n",
        "  epsilon=K.random_normal(shape=(K.shape(z_mean)[0],latent_dim),mean=0,stddev=1.)\n",
        "  return z_mean + K.exp(z_log_var)*epsilon\n",
        "\n",
        "z=layers.Lambda(sampling)([z_mean, z_log_var])"
      ],
      "metadata": {
        "id": "FTuXcv2369mo"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Layer to map latent vector to image\n",
        "decoder_input =layers.Input(K.int_shape(z)[1:])\n",
        "\n",
        "x=layers.Dense(np.prod(shape_before_flattening[1:]),activation='relu')(decoder_input)\n",
        "x=layers.Reshape(shape_before_flattening[1:])(x)\n",
        "x=layers.Conv2DTranspose(32,3,padding='same',activation='relu',strides=(2,2))(x)\n",
        "x=layers.Conv2D(1,3,padding='same',activation='sigmoid')(x)\n",
        "\n",
        "decoder = Model(decoder_input,x)\n",
        "z_decoded=decoder(z)\n",
        "decoder.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aQ-TA-NF9rOW",
        "outputId": "dc20ef3d-13ed-4b0e-b9f0-b99513b708bd"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 2)]               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 12544)             37632     \n",
            "                                                                 \n",
            " reshape (Reshape)           (None, 14, 14, 64)        0         \n",
            "                                                                 \n",
            " conv2d_transpose (Conv2DTra  (None, 28, 28, 32)       18464     \n",
            " nspose)                                                         \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 28, 28, 1)         289       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 56,385\n",
            "Trainable params: 56,385\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomVariationalLayer(keras.layers.Layer):\n",
        "  def vae_loss(self,x,z_decoded):\n",
        "    x=K.flatten(x)\n",
        "    z_decoded=K.flatten(z_decoded)\n",
        "    xent_loss=keras.metrics.binary_crossentropy(x,z_decoded)\n",
        "    kl_loss=-5e-4*K.mean(1+z_log_var-K.square(z_mean)-K.exp(z_log_var),axis=-1)\n",
        "    return K.mean(xent_loss+kl_loss)\n",
        "  \n",
        "  def call(self, inputs):\n",
        "    x=inputs[0]\n",
        "    z_decoded=inputs[1]\n",
        "    loss=self.vae_loss(x,z_decoded)\n",
        "    self.add_loss(loss, inputs=inputs)\n",
        "\n",
        "y=CustomVariationalLayer()([input_img,z_decoded])"
      ],
      "metadata": {
        "id": "ldc_J8VS-ZWq"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.datasets import mnist\n",
        "\n",
        "vae=Model(input_img,y)\n",
        "vae.compile(optimizer='rmsprop',loss=None)\n",
        "vae.summary()"
      ],
      "metadata": {
        "id": "wzO8S6F_AXS6",
        "outputId": "c1a9fe65-ce15-417b-bb94-4fd240182437",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 28, 28, 1)]  0           []                               \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 28, 28, 32)   320         ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 14, 14, 64)   18496       ['conv2d[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 14, 14, 64)   36928       ['conv2d_1[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 14, 14, 64)   36928       ['conv2d_2[0][0]']               \n",
            "                                                                                                  \n",
            " flatten (Flatten)              (None, 12544)        0           ['conv2d_3[0][0]']               \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 32)           401440      ['flatten[0][0]']                \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 2)            66          ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 2)            66          ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " lambda (Lambda)                (None, 2)            0           ['dense_1[0][0]',                \n",
            "                                                                  'dense_2[0][0]']                \n",
            "                                                                                                  \n",
            " model (Functional)             (None, 28, 28, 1)    56385       ['lambda[0][0]']                 \n",
            "                                                                                                  \n",
            " custom_variational_layer_1 (Cu  multiple            0           ['input_1[0][0]',                \n",
            " stomVariationalLayer)                                            'model[0][0]']                  \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 550,629\n",
            "Trainable params: 550,629\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train,_),(x_test,_)=mnist.load_data()\n",
        "x_train=x_train.astype('float32')/255\n",
        "x_train=x_train.reshape(x_train.shape+(1,))\n",
        "\n",
        "x_test=x_test.astype('float32')/255\n",
        "x_test=x_test.reshape(x_test.shape+(1,))"
      ],
      "metadata": {
        "id": "RhbAxIMDBF0c"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vae.fit(x=x_train,y=None,\n",
        "        shuffle=True,\n",
        "        epochs=10,\n",
        "        batch_size=batch_size,\n",
        "        validation_data=(x_test, None))"
      ],
      "metadata": {
        "id": "yMwF1gTNB6pr",
        "outputId": "a4a9aa98-86ac-46a2-a3ed-8ac677db3228",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 864
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-715d05f02708>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         validation_data=(x_test, None))\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1127\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1128\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1129\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1130\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 878, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 867, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 860, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 810, in train_step\n        y, y_pred, sample_weight, regularization_losses=self.losses)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/compile_utils.py\", line 240, in __call__\n        total_loss_metric_value, sample_weight=batch_dim)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/metrics_utils.py\", line 73, in decorated\n        update_op = update_state_fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/metrics.py\", line 177, in update_state_fn\n        return ag_update_state(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/metrics.py\", line 467, in update_state  **\n        update_total_op = self.total.assign_add(value_sum)\n    File \"/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py\", line 83, in asarray\n        return array(a, dtype, copy=False, order=order)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/keras_tensor.py\", line 256, in __array__\n        f'You are passing {self}, an intermediate Keras symbolic input/output, '\n\n    TypeError: You are passing KerasTensor(type_spec=TensorSpec(shape=(), dtype=tf.float32, name=None), name='tf.math.reduce_sum/Sum:0', description=\"created by layer 'tf.math.reduce_sum'\"), an intermediate Keras symbolic input/output, to a TF API that does not allow registering custom dispatchers, such as `tf.cond`, `tf.function`, gradient tapes, or `tf.map_fn`. Keras Functional model construction only supports TF API calls that *do* support dispatching, such as `tf.math.add` or `tf.reshape`. Other APIs cannot be called directly on symbolic Kerasinputs/outputs. You can work around this limitation by putting the operation in a custom Keras layer `call` and calling that layer on this symbolic input/output.\n"
          ]
        }
      ]
    }
  ]
}